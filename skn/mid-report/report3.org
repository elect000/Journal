#+TITLE: モジュール分割された日本語対話システムの作成
#+SUBTITLE: 
#+AUTHOR: 江畑 拓哉
# This is a Bibtex reference
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil arch:headline ^:nil
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:nil e:nil email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:nil title:t toc:nil todo:t |:t
#+LANGUAGE: ja
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 26.1 (Org mode 9.1.4)
#+LATEX_CLASS: skn
#+LATEX_CLASS_OPTIONS: 
#+LaTeX_CLASS_OPTIONS:
#+LATEX_HEADER:  \addbibresource{reference.bib}
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP: indent overview inlineimages

#+LATEX: \maketitle
#+LATEX: \pagestyle{empty}

* 序論
  現在世界では様々な目的を持った対話システムが研究されている。主にそれは、ユーザを何らかの目標に導くためのタスク指向システム、対話そのものを目的とした非タスク指向システムの二種類に分かれている。またこの二つを組み合わせたシステムも開発されており、 Apple 社の Siri \footnote{http://www.apple.com/ios/siri} がこれに該当する。\\
  　本研究では上記の二つを満たし、かつより低コストなシステムを構築するため、様々な目的を持ったモジュールを作成し組み合わせる手法を提案する。尚ここで言う低コストとは、学習時間やモデルの更新の容易さなどの意味で用いている。
* 研究概要
** 研究目標
   #+CAPTION: システム概図
   #+NAME: fig:label1
   #+ATTR_LATEX: :width 14cm
   [[./figure2.jpg]]
   本研究は 図1 のシステムを構築することを目的とする。\\
   　例えばそのエージェントの名前に関する質問が来た場合は、 Question Detection を通り Answer Generation で自分の名前に関する文章を生成し、 Style Transfer を経由して回答を出力する。ゲームに関する入力が来た場合は、 Question Detection を通過し Sentence Categorization で ゲームに関する Topic Dialogue にアクセスし出力する。最終的にそれらの情報を Style Transfer を通して出力する。Style Transfer とは口調変換であり、エージェントに様々なペルソナを持たせるために用いられる。そのペルソナはエージェントの外見などと同期することでより対話感を出すことが出来ると考えている。またエージェントは天候などの環境データ、今までの対話データからそのステータスが変化することを想定しており、例えばあるものに対する好感度はそれまでの対話から形成されるようにする。
** 利用するデータ
　このシステムにおいて必要とするデータは主に二種類である。
- Style Transfer を行うためのデータ\\
  　このデータには、元の文と付与された文のペアを集めたものと、スタイルが付与されていない文の群と付与された文の群を用いるものがある。現在の進捗としてはデータ生成の問題から前者を用いている。
- 対話を行うためのデータ\\
  　入力文と出力文のペアを集めたものである。収集手法として、1. 実際に手作りする 2. アニメや演劇などから集める 3. SNS から集める を行い、特に後者２つについては有効なデータをフィルタリングする手法を研究している。
** それぞれのモジュールに適用した手法と今後の予定
- Question Detection\\
  　入力文に対して LSTM を適用し質問番号を出力する手法によって殆どの分類が行えることがわかった。
- Answer Generation\\
  　あらかじめ用意したテンプレートにエージェントのステータスから取り出した値を当てはめることで生成する。
- Sentence Categorization\\ 
  　SCDV cite:scdv のような手法や、sentiment analysis で使われる手法 cite:cnnsa を検討している。また単語埋め込みとして、 fasttext cite:fasttext や Word2Vec を採用したいと考えている。いずれも十分なサイズのデータを収集できておらず実験が出来ていない。代替としてアニメの台本から入出力のペアを切り出した対話として成立しているデータ、一般的な対話を集めたデータを用いて RNN, CNN を用いた二値分類実験を行い、後者で8割5分ほどの検出をすることが出来た。
- Topic Dialogue\\
  　日本語でも Sequence to Sequence cite:seq2seq のような手法を用いた様々な取り組みが行われているが、芳しい結果を得られたものは少ない。しかし公開されているデータセットを確認すると、英語のデータセットと比較して、入力と出力のペアで意味が通らないものがあるなど、有効なデータセットとは言えなかった。自作の日常会話を集めたデータセットで Sequence to Sequence を用いた実験をしたところ、データセットの近傍の入力に対し意味のある出力を得た。ところがデータ量が少ないため(1k対話程度)これをいかに増やしていくかが今後の課題となる。
- Style Transfer\\
  　スタイルを付与されていないものと、付与されたもののペアをデータセットとして、 Sequence to better Sequence cite:seq2bseq と、DAE cite:dae から着想を得た提案手法と CopyNet cite:dae を用いて実験を行った。結果として前者2つはチューニングが難しい代わりに自然な文を生成することに成功し、後者は比較的高速に文を生成できる他にある程度未知語に対応可能であった。今後 Sequence to better Sequence に CopyNet を組み合わせたシステムを提案したいと考えている。
- データ収集について\\
  　手作りでデータセットを作成する手法に関しては誤字脱字や意味の通らない文を含まない理想的なデータになるように打ち込んでいる。アニメや演劇からの収集については、長すぎる文は必要な部分のみにし、専門的過ぎる文は削除している。こちらは著作権などの問題があるため、この対処を調査中である。SNS からのデータの収集については Twitter を用いているが、ノイズの多いデータが混じっているため、そのデータクリーニングについて既存の手法 cite:twitercleaning を参考にしながら研究している。
- ステータス更新を行う手法\\
    　文章に関しては Word2Vec cite:word2vec や fasttext cite:fasttext を用いた極性判定を用いて実験する予定だ。
#+LATEX: \printbibliography

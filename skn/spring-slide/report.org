
#+LATEX_CLASS_OPTIONS: [dvipdfmx]
#+TITLE: 卒業論文発表
#+AUTHOR: 江畑 拓哉
#+EMAIL: s1611350@u.tsukuba.ac.jp
#+DATE: 2019-1-31 Thr
#+DESCRIPTION:
#+KEYWORDS:
#+BEAMER_ENV: dvipdfmx
#+SUBTITLE:
#+OPTIONS: ':nil *:t -:t ::t <:t \n:t ^:t arch:headline author:t
#+OPTIONS: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:t f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+OPTIONS: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.2.2 (Org mode 9.1.14)
#+OPTIONS: H:2
#+BEAMER_FRAME_LEVEL: 2
#+LATEX_CLASS: beamer
#+BEAMER_THEME: Marburg
#+LATEX_HEADER: \usepackage{amsmath, amssymb, bm}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage[textfont=scriptsize, labelfont=scriptsize]{caption}
#+LATEX_HEADER: \setbeamertemplate{footline}[frame number]
#+LATEX_HEADER: \useoutertheme[left, height=0pt, width=0.2\paperwidth]{sidebar}
#+LATEX_HEADER: \usepackage[backend=biber, bibencoding=utf8, style=authoryear]{biblatex}
#+LATEX_HEADER: \addbibresource{../last-report/reference.bib}
* 研究概要
** 
   　昨今自然言語処理において対話システムを構築する試みを様々な団体が行っている。本研究ではその流れに乗り、特にキャラクタ性のある日本語を用いた対話システムの構築を目指す。
  　尚対話システムを構築する手法として、複数の小さな問題に分割して解決するというものがある。本研究ではその手法を採用し、複数の小問題を設定し、それぞれについて研究を行った。
 \begin{wrapfigure}[3]{r}[1em]{3cm}
   \centering
   \includegraphics[keepaspectratio, width=3cm]{img/minecraft.jpg}
   \caption{イメージ}
   \end{wrapfigure}
   　更に学習データである日本語データについて収集を行い、そのデータの性質・考えられる前処理手法を調査した。

* 先行研究
** 
     　先行研究としては、Microsoft社の女子高生AI「りんな」(\cite{rinna_article}) の他、Amazon Alexa Prize という Amazon Alexa の内部システムについてのコンテストにおける作品(\cite{Gunrock} や \cite{1804.10202})を挙げることが出来る。
* 想定する対話システムの概要図
** 
   　以下のようなシステムを想定し、それぞれに必要になるテーマのうちの5つを本研究では取り上げ研究を行った。
   
#+ATTR_LATEX: :width 10cm
#+CAPTION: 本研究のシステム全体像
#+NAME: fig:system-abst
[[../last-report/img/figure3.png]]
* 日本語データの取り扱いについて
** 研究概要
   　特に日本語の自然言語処理を研究する際に、その利用可能なデータが少ない、最適な前処理手法が確立されていないという問題がある。
   　本テーマでは、対話システムを構築することを前提に、まずTwitterのデータ、NTTの雑談対話コーパス、名大コーパスのデータを観察し、どのようなデータがあるのかを調査し、次に Wikipedia コーパスをデータとして、前処理 漢字 $\rightarrow$ かな変換 を行い、単語分散を得、その効果を実験した。
** 結果1) データの調査
 - Twitterデータについてはテキストを通した日常的な対話、発話が直に得られたものの、絵文字・顔文字についての処理について深く踏み込まなければならないこと、データの偏りが大きいことがわかった。
 - 名大コーパスについては現実の音声会話であるため、テキストの対話システムを構築するデータとしてはやや不適であると考えられた。
 - NTTの雑談対話コーパスについては対話システムのログから得られたデータであったため、本研究のためのデータとして直ちに有効であるとわかった。
** 結果2) 日本語データの前処理手法の提案
 - 漢字 $\rightarrow$ かな 変換を行ったことで、語彙数の減少は見られたが、単語分散を獲得する学習(fasttext (\cite{Bojanowski2017EnrichingWV}) を用いた)で損失が増えてしまうという問題が発生した。しかし得られた単語分散で極性判定を行った(CNN-LSTM (\cite{Sainath2015ConvolutionalLS}) を用いた)ところ、いずれも性能はほとんど変わらなかった。
 - 単語分散を用いてある単語の類似単語を調査したところ、変換をした場合は音声的に近い単語を類似単語として集めることが出来た。
* 文抽出を念頭においた不均衡分散・サイズの分類問題
** 研究概要
   　対話システムを構築する上で、任意の入力に対していくつかの特定のクラス(ex. 質問や注文)に属しているか、或いはどのクラスにも属していないのかを判定したい、という場面が出てくる。この場面を想定した場合に、一般的なクラス分類では困難であることが伺える。本テーマではこの問題に対して、まず文の類似度を学習し、次に入力文に対して各クラスのサンプルを数個用いてそれぞれの類似度を測り、その要約統計を取ることで入力がどのクラスに所属しているのかを判定する手法を提案する。
** 結果
   　BERT(Bidirectional Encoder Representations from Transformers \cite{Devlin2018BERTPO}) と呼ばれる言語モデルを文類似度を測るようにファインチューニングした。データには各クラスを設定し、それぞれに学習データを平均7文作成し、各文の組み合わせを取ったものを用いた2。ここにおける正答率 (accuracy) は 96 % 、損失 (cross-entropy) は 0.132 と良い成績を得ることが出来た。
   　しかしクラス分類を行った際に要約統計を行ったところ、同じカテゴリ(例えば天候に関するカテゴリ)に属するようなクラスの文うまく分類できなかった。原因としては組み合わせを用いてデータを作成した際に、負のサンプルを正のサンプル数と揃えるため切り落としたこと、クラス外のデータを用意できなかったことが考えられる。
** 
  　赤が正解(嫌いな食べ物を尋ねる)で、紫が予測(好きな食べ物を尋ねる)である。
\begin{wrapfigure}[10]{r}[1em]{5cm}
  \centering
  \includegraphics[keepaspectratio, width=5cm]{img/error-detect-class.PNG}
  \caption{うまくいかなかった例}
  \end{wrapfigure}

  　縦軸は要約統計(平均)を取った類似度であり、横軸ははそれぞれのクラスの id を示している。
  　このことから、キー
ワードを用いた分類も
判定材料に加えた方が
良いと考えられる。
* 機械翻訳モデルを用いた対話モデル
** 研究概要
   　昨今の自然言語処理の、特に機械学習(深層学習)を用いる界隈では、機械翻訳モデルの研究が盛んである。この分野で得られたモデルを対話システムの、特に反射応答、常識的な応答に対して用いようというのが本テーマのモチベーションである。本テーマでは特に古くから用いられている Sequence to Sequence Attention(\cite{Luong2015EffectiveAT}) と最近登場し注目を浴びている Transformer(\cite{Vaswani2017AttentionIA}) の2つのモデルを用いて実験を行った。
** 結果
   　Sequence to Sequence Attention モデルに対して Transformer は実行時間や計算コストが低く、BLEU スコア(主に機械翻訳などの自然言語処理で用いられる精度指標) が高いことがわかった。
   #+ATTR_LATEX: :environment longtable :align |c|c|
   #+CAPTION: 学習に用いたデータのBLEUスコア
  |--------------+-------------|
  |              | BLEU スコア |
  |--------------+-------------|
  | Seq2Seq Attn |       66.92 |
  | Transformer  |       77.11 |
  |--------------+-------------|
   #+ATTR_LATEX: :environment longtable :align |c|c|
   #+CAPTION: 学習外のデータについてのBLEUスコア
  |--------------+-------------|
  |              | BLEU スコア |
  |--------------+-------------|
  | Seq2Seq Attn |       61.80 |
  | Transformer  |       64.33 |
  |--------------+-------------|
** 
#+LATEX: \tiny
#+ATTR_LATEX: :caption \caption{データセットの入力と出力の例} :environment longtable :align |c|c|
|----------------------------------+------------------------------------------|
| 入力                             | 出力                                     |
|----------------------------------+------------------------------------------|
| チーズケーキは好きですね。       | チーズケーキの美味しい店を知っています。 |
| おはよー。熱中症に気をつけて。   | おはようございます。                     |
| テレビは民主党支持が多いですね。 | そんな事はないでしょ?                    |
| プレイは普通です。               | どんなスポーツをされますか?              |
| 晴れの日は嫌い?暑い?             | 晴れの日がいいですね。                   |
| ですよね。                       | はい。                                   |
|----------------------------------+------------------------------------------|

#+LATEX: \tiny
#+ATTR_LATEX: :caption \caption{Sequence to Sequence Attention と Transformer によって得られた出力} :environment longtable :align |c|c|
|------------------------------------------+------------------------------------------|
| Seq2Seq Attn                             | Transformer                              |
|------------------------------------------+------------------------------------------|
| チーズケーキの美味しい店を知っています。 | チーズケーキの美味しい店を知っています。 |
| 漫画は読みますか。                       | おはようございます。                     |
| そんな事はないでしょ?                    | そんな事はないでしょ?                    |
| どんなスポーツをされますか?              | どんなスポーツをされますか?              |
| 晴れの日がいいですね。                   | 晴れの日がいいですね。                   |
| 夏って感じがします。                     | 私もスポーツが好きです。                 |
|------------------------------------------+------------------------------------------|

* 文のスタイル変換
** 研究概要
   　対話システムの開発において``人間らしさ"はユーザに対し親密感を与えることが出来、より円滑なコミュニケーションを促進することが出来ると考えられる。また日本語は英語に比べ、語尾のみの変換でも、比較的にペルソナを象ることが出来ると考えられる形態を持っている。そのため本テーマでは特に語尾を中心とした文のスタイル変換を提案し、これを行うために(英語での)スタイル変換を目的とした Sequence to Better Sequence(\cite{s2bs}) というモデルと これに Denoising Autoencoder(\cite{dae}) を加えたモデル、CopyNet(\cite{Gu2016IncorporatingCM}) という機械翻訳・文要約の問題設定で用いられるモデルを用いて実験した。
** 結果
   　十分なデータを用意することが出来なかったため、Sequence to Better Sequence とこれに Denoising Autoencoder を加えたものとの結果に有意な差を見ることが出来なかった。こちらは語尾のみの変換にとどまらず文全体も変換するという結果が得られ、大規模なデータを用いた場合の更なる興味深い結果を期待できる。
   　CopyNetについては語彙外の単語に対してもほとんど適切に(そのまま出力に受け流すという形で)対処することが出来た。
** 
   #+LATEX: \tiny
   #+ATTR_LATEX: :caption \caption{文スタイル変換の実験結果} :environment longtable :align |c|c|c|
|---------------+--------------------------+--------------------------------|
| 実装          | 入力                     | 出力                           |
|---------------+--------------------------+--------------------------------|
| S2BS          | おはようございます。     | おはよう。                     |
|               | 応援する。               | 応援してる。                   |
|               | 今日は寒かった。         | 今日は寒かった。               |
|               | 夕飯は？                 | 夕飯はどうしようか？           |
|               | 早く寝たい。             | お風呂に入ろう。               |
|               | 何か不安だなぁ。         | 何か口に入れてはどうでしようか |
|---------------+--------------------------+--------------------------------|
| S2BS with DAE | S2BSと同じ結果が得られた |                                |
|---------------+--------------------------+--------------------------------|
| CopyNet       | おはようございます。     | おはよう。                     |
|               | 今日は良い天気ですね。   | 今日は良い天気。               |
|               | こんにちは。             | こんにちは。                   |
|               | 頑張るぞい！             | 頑張るぞい！                   |
|               | 進捗どうですか？         | 進捗どう？                     |
|---------------+--------------------------+--------------------------------|
   
* CoLAタスクを応用した対話システムのエラー検知
** 研究概要
   　深層学習をはじめとした機械学習を用いた文生成においてはその精度が不安要素として挙げられる。本テーマでは特に機械学習モデルから生成されてしまった不自然な文を特定することを扱い、その後の何らかのエラー処理(例えばその生成文に代わって``よくわかりません''とするなど)に繋げる足がかりとする。
** 結果
   　BERT と呼ばれる言語モデルを自然な文と自然でない文の2値分類するようにファインチューニングした。データには 機械翻訳モデルを用いた対話モデル で得られた出力を手動でラベリングしたものを用いた。結果としては正答率 (accuracy) が 61 % 損失が(cross-entropy) 0.712082 であったが、自然な文と自然でない文を2値分類する問題の中では優秀な精度を得られた。但し難しい学習であったためか、学習がやや不安定になっていることが確認された。
** 
   #+CAPTION: 対話システムのエラー検知の実験結果 における epoch と 精度の変化 
   #+NAME: fig:112
   #+ATTR_LATEX: :width 7cm
   [[../last-report/img/cola.PNG]]
* 結論
** 
  　必要な要素それぞれにを大まかに総括すれば、用意できたデータ数を考慮すれば、十分な結果であったと考えられる。しかしこれが大規模なデータに対してどのような結果になるのかは未知数であるし、そもそも第規模なデータを確保できるかも不明である。その点から本研究では取り扱わなかったルールベースのような技術も取り込む必要があると考えられる。
  　また本研究では扱わなかった分野の研究や、各テーマで考察された新たな問題に対しても研究する必要がある。
* 

#+LATEX: \printbibliography


#+TITLE: モジュール分割された日本語対話システムの研究
#+SUBTITLE: 
#+AUTHOR: 
# This is a Bibtex reference
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil arch:headline ^:nil
#+OPTIONS: author:nil broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:nil e:nil email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:nil title:nil toc:t todo:t |:t
#+LANGUAGE: ja
#+SELECT_TAGS: export 
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 26.1 (Org mode 9.1.4)
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, dvipdfmx]
#+LATEX_HEADER: \usepackage{amsmath, amssymb, bm}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage{pxjahyper}
#+LATEX_HEADER: \hypersetup{colorlinks=false, pdfborder={0 0 0}}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[backend=biber, bibencoding=utf8, style=authoryear]{biblatex}
#+LATEX_HEADER: \usepackage[top=30truemm, bottom=30truemm, left=25truemm, right=25truemm]{geometry}
#+LATEX_HEADER: \usepackage{ascmac}
#+LATEX_HEADER: \addbibresource{reference.bib}
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP: indent overview inlineimages


* 序論
#+LATEX: \pagenumbering{arabic}
** 研究背景及び目的
   ある目的に対してより完璧に(accuracyが高くなるように)命令を実行をする Artificial Intelligence が求められている昨今のAI競争の時代に対し、自然言語処理やゲームAIのようなタスクは極めて複雑な課題を抱えている。例えばそれは``言葉''という問題である。これは人間がコンピュータに正解となるものを提供することが極めて難しく、``なんとなく良い感じに''目的を達成してくれることを期待することが多い。この問題に対処するための手段として、入手でき得る限りの大規模なデータを用意して中心極限定理的に尤もらしい中心部を得る方法や、とにかく何らかの単一のモデルに押し込めて問題を解くという方法 [fn:hred] がある。それに対して、データそのものを一旦精査・前処理すること、問題を整理・分解しそれぞれを解くことも研究 [fn:multimordule] として存在している。\\
   　自然言語処理の、特に対話システムについて考えたとき、小問題に分割した上で対話システムを達成した例として、例として Amazon Alexa Prize [fn:alexaprize] というコンテストやMicrosoft社が研究・開発している``りんな'' [fn:rinna] を挙げることができる。これらは対話を行うという問題に対して小さな部分問題を解くタスクを設定し、それぞれを組み合わせることで元の問題を解くというスタイルを取っている。\\
   　本研究ではこれらを参考に、日本語の対話システムを作成するという問題に対して小問題を設定しそれを解くための手法を提案・実験する。またその前準備としてデータ収集に絡めて日本語データとその前処理について考察する。尚本研究が最終的に望むものは、キャラクタ性を持った対話可能なエージェントを作ることであることを強調する。\\
   　もう少し言及すると、本研究ではデータからモデルにかけて5つの少テーマについて研究を行った。概要をそれぞれ説明すると以下のようになる。
   1. 日本語データの取り扱いについて\\
      　我々は一般に日本語を話しており、それを用いた対話システムの構築が本研究の主目的である。しかし機械学習等のデータセットや実験で多く使われているのは、日本語とは使っている文字や文型で大きく異なっている、英語のものが多い。その前提のもとで日本語のデータ、特にセンテンスに対して、どのような性質があるのかを調査し、また提案する漢字→ひらがな変換という前処理とそれによって得られる性質についても議論を行う。
   2. 文抽出を念頭においた不均衡分散・サイズの分類問題\\
      　テキストのカテゴリ分類を考えたとき、一般には $n$ 個のカテゴリの中から任意の文が入力されることを想定している。今回はそれとはやや問題設定が異なり、いくつかの文をカテゴリ $1 \cdots n-1$ 、それ以外をカテゴリ $n$ として扱うことを主問題した。しかしデータを設定・収集することが困難であったため、一部画像認識の問題として議論を行う。
   3. 機械翻訳システムを用いた対話モデル\\
      　一対一対話を行う際に、機械翻訳システムを用いることがある。今回はそれを、問題を文脈に依存しない発話に対する反応を学習することに再設定し、Transformer という2017年12月時点で SOTA (State-Of-The-Art 最高水準) を獲得した機械翻訳の手法を用いて実験、有名な手法である Sequence to Sequence Attention を用いた一対一対話モデルと比較を行う。
   4. 文のスタイル変換\\
      　文のスタイルとは、例えば口調や訛り、書き言葉や話し言葉といったものを指す。これは日本語で特に顕著に見られるもので、テキスト上でもこれを確認することで相手のペルソナをある程度想定することができる。本研究が日本語を対象としていること、キャラクタ性を持たせたいというモチベーションがあることから文に特定のスタイルを持たせることを問題として取り上げる。
   5. CoLAタスクを応用した対話システムのエラー検知\\
      　対話システムを小問題に分割して解く弊害として、それぞれの問題でエラー(不適切な出力)が出てしまうというものがある。これに対処するため、特に何らかのモデルから生成された文に対しそれが自然であるかどうかを評価するモデルを作成し実験する。

*** abstract :noexport:
  　まず受付やオンラインチャットなどにおいて対話システムの需要が増えていること、Amazon AlexaやSiriなどを例に出して説明する。次にキャラクタ性を持ったマルチモーダル対話システムとして、りんなを例に上げる。\\
  　その実装例として、Amazon Alexa Prize のコンテストを例に出す。\\
  　本研究の目的として、日本語環境下で、りんなのような機能を持つシステムを構築すること、ゲームAIへの転用などを視野にいれていることを説明する。そしてシステムの概要として、対話システムという大問題に対して、いくつかの小問題に分割し、それらを組み合わせるモジュール分割という手法を用いることにしたことを説明する。
[fn:rinna] https://twitter.com/ms_rinna
[fn:alexaprize] https://developer.amazon.com/alexaprize
[fn:hred] HRED (\cite{1507.02221}) や VHRED (\cite{1605.06069}) があるが、発話の多様性を得ること(一般的な受け答えを学んでしまい、同じような文ばかり生成してしまう)やデータを十分に集めることが難しいなど課題がある。
[fn:multimordule] 日本で人気を得ている ``マルチモーダルエージェントAI'' とは、複数のソースから問題を見直すという特徴があるが、これは複数のモデルを使っているという意味で同じではあるが、問題を分割しようとしているわけではないという点でこの研究と大きく違うと言えるだろう。
** 本論文の構成
第1章に本論文の概要とその構成について説明を行い、第2章で関連研究を紹介し、第3章で本研究で掲げるシステムの全体像を示す。そして第4章から第9章にかけては [[研究背景及び目的]] で述べたテーマについての順に議論する。その後付録として補足をまとめたものを 第10章 として示す。最後に議論として本論文のまとめ、今後の展望について述べる。

*** abstract :noexport:
   　1章として論文の導入をしていること。2章で対話システムの関連研究として1章の研究背景で紹介した(Amazon Alexa Prizeやりんな)の概要を説明していること。3章として対話システム全体の実装として目標としている構成図を示していること。4章については日本語のデータをどのように扱うべきか考察したこと。5章から8章にかけてはそれぞれのモジュールに対する研究について説明をしていること。9章に対してはそれぞれの章で説明が不足しているであろう内容を補足するための付録であること。を説明する。
* 対話システムの関連研究
:PROPERTIES:
:CUSTOM_ID: relation-reserch
:END:

対話システムの関連研究としては、 [[研究背景及び目的]] で述べたように Amazon Alexa Prize というコンテストや、Microsoft社のりんなを挙げることができるだろう。Microsoft社のりんなは日本語雑談対話(\cite{rinna_article}) を実現しており、2018年現在Twitterなどで活動をしている。Amazon Alexa Prize は Amazon Alexa という音声会話を行うことのできる端末に搭載する対話システムを競う大会である。評価対象はユーザの印象であり、別の指標として対話時間が公開される。2018年度のAmazon Alexa Prizeでは平均10分程度の対話を行うことの出来たシステム [fn:aap] が優勝した。顔や体といったテキスト以外の情報を用いることの出来ない対話システムでこのような結果が得られたことは注目すべきことである。\\
　いずれも複数のモデルを組み合わせて構成されており、例えば言語理解部と文生成部、そして本研究で取り扱わないものとしては、音声理解部と音声生成部を挙げることができる。またりんなに関してはそれに加えて画像認識部などの対話以外の [fn:rinna2] システムも構築している [[[fig:RINNA-FRAMEWORK][Figure 1]]] 。

#+ATTR_LATEX: :width 12cm
#+CAPTION: りんなのフレームワーク
#+NAME: fig:RINNA-FRAMEWORK
[[./img/rinna-framework.png]]
#+LATEX: \newpage
[fn:aap] 2018年度優勝は カルフォルニア大学デイビス校のチームが開発したの Gunrock というシステムであり、また2017年度優勝はワシントン大学のチームが開発した Sounding Board というシステムである。この2つについての詳細は [[#extra_rsearch]] で紹介する。なぜこれらを追実装しなかったのかという疑問もあるかもしれないが、いずれも大規模なデータを必要とする (例えば10Mを超える会話データ) ため、個人でそれを実装することは不可能である。
[fn:rinna2] 対話をテキストやそれを示す音声のみのコミュニケーションと定義した場合。実際には対話には身振り手振り、表情といった要素が複雑に絡んでいる。そのため2017年頃からは、表情を考慮した対話システムが提案され(\cite{1812.01525})研究されている。

** abstract :noexport:
  　関連研究として、Amazon Alexa Prizeの問題設定の説明、 2018 年、2017年の最優秀賞団体がモジュール分割して問題を解決したことを説明する。りんなの概要についても紹介する。

* 想定する対話システムの全体像
 以下に本研究で想定する対話システムの全体像を示す[[[fig:system-abst][Figure 2]]]。\\
　このシステムでは入力としてテキストと、環境情報を得る。このシステムにおける環境情報とはこのシステムが組み込まれているエージェントが居る場所の環境(天候や気温・湿度)、エージェントの内部状態(メモリ使用率等)を指す。これはテキストを用いた人対人の対話をイメージしたもので、つまり相手の居る環境、相手の体調をそれぞれ置き換えたものになる。またAnswer Generationに用いる所謂個人データのようなものもエージェントの内部に持っているものとする。本論文で扱うものは、この内の Sentence Detection / Sentence Categorization / Topic Dialogue / Style Transfer である。またTopic Dialogue から Style Transfer への矢印・Answer Generation から Style Transfer への矢印・Style Transfer から Output への矢印におけるエラー検知についても議論する。

#+ATTR_LATEX: :width 12cm
#+CAPTION: 本研究のシステム全体像
#+NAME: fig:system-abst
[[./img/figure3.png]]

- Sentence Detection [該当部:[[#inbalance-categorization][文抽出を念頭においた不均衡分散・サイズの分類問題]]]\\
  　ある特定の文を取り出す。取り出された場合はどの意味として取り出されたのかという情報とともに、Answer Generationへ向かい、取り出されなかった場合には付加情報なしで Sentence Categorizationへ入力を受け流す。
  　最終的にはほとんどの文をここで抽出し、それに対する返答を Answer Generation でエージェントの内部状態ないし外部知識ベースを参照しながら生成する。
- Sentence Categorization [該当部:[[#deal-japanese-data][日本語データの取り扱いについて]]]\\
  　文を大雑把にカテゴリ分類する。例えばそれは livedoor news corpus [fn:ldnc] で議論されるような スポーツ/IT/家電 といったようなカテゴリである。ここでカテゴリ分類された文はそれぞれ対応する Topic Dialogue に流される。
- Topic Dialogue [該当部:[[#con-model-use-mt][機械翻訳システムを用いた対話モデル]]]\\
  　与えられたカテゴリに対する一対一応答を行う。例えばゲームについての話題を受け持つ Topic Dialogue はゲームに関する入力文を期待しており、それに対する出力を学習しているものとする。そのモデルはエージェントのペルソナに応じて置換することが可能であり、例えば好きなゲームカテゴリについての好意的なデータを多分に含んだデータセットで訓練した Topic Dialogue はそのゲームカテゴリが好きな(好きになった)エージェントが持つことになる。
- Style Transfer [該当部:[[#style-transfer][文のスタイル変換]]]\\
  　文のスタイルを変換する。ここで言う文のスタイルとは例えば書き言葉や話し言葉、各ペルソナに基づいた語尾変化を示す。
- エラー検知についての議論 [該当部:[[#cola-error-handling][CoLAタスクを応用した対話システムのエラー検知]]]\\
  　上記のシステムで発生するエラーデータと正常なデータを分類する。
[fn:ldnc] https://www.roundhuit.com/download.html#ldcc
** abstract :noexport:
  　全体像図のグラフを示す。
  　それぞれの問題をリストとして示す。

* 日本語データの取り扱いについて
:PROPERTIES:
:CUSTOM_ID: deal-japanese-data
:END:
日本語データは英語データに比べていくつかの問題を抱えている。問題の例としては、文字の数が多すぎること、スペースといった意味ごとの分割がないこと、容易にペルソナを特定できるような多彩な語尾変化があること、多国語も日本語であるかのように用いること、同意同音の語でも様々な表記方法があることが挙げられる[fn:spacesplit]。\\
　また一般に公開されている対話データセットを対話テキストのみで学習させると想定したとき、背景知識の欠如を指摘せざるを得ない。更に言えば日本人の特徴として``言外にわかり合う''というコミュニケーションスタイルも問題を難しくしていると言えるだろう。\\
　この章では上記の問題があることを公開されているデータセット、Twitterから収集したデータセットを用いて調査するとともに、``漢字をかなに変換する''という前処理を用いることでどのようにデータの性質が変化するのかを、単語分散を得るというタスクについて実験する。\\
　尚本研究では、形態素解析にはMeCab 0.996、単語辞書として mecab-ipadic-neologd 20181112-01 を用いた。特にTwitterのようなデータは流行語や新語に対応するため、単語辞書を定期的に更新する必要がある。
[fn:spacesplit] 前2つに関しては、中国語も共通して抱えている問題と言える。
** abstract :noexport:
  　日本語データは英語データに比べていくつかの問題があること。その例として。語尾の多彩な変化や漢字かな問題があることを紹介する。また一般に公開されている対話データセットをどのように用いるべきなのかについての考察を行ったこと、漢字かな問題に対して単語分散を得るための手法を二種類想定し、それぞれの性質を比較する。
** 調査) 発話データ
発話データとして、2018年12月25日 23:00頃 から翌 26日 10:00頃 までに収集した7万件のTwitterデータを収集し、その性質を観測した。\\
　データの収集手法としては Twitter 社が公開している API を用い、日本のユーザから呟かれている内容を集めるものとした。この処理によって生データが 77,285 発話得られた。
*** フィルタ
:PROPERTIES:
:CUSTOM_ID: filter
:END:

データを収集するにあたり、タグや宛名、URLリンクと言った Twitter に特有な部分を省いた。その上で、4文字以上、60文字以下のデータをすべて抽出し、データを 54,368 発話にした。\\
　Twitterに特有な部分を省いた理由として、全体の目的から考えてTwitterデータに特化させる必要がなかったこと、タグは時系列で発生・消滅すること、宛名に関してはそのユーザの背景情報が必要になることが容易に想像できること、URLリンクを発話として認めるべきではないと考えたこと[fn:url-link]を挙げる。\\
　また文字数でフィルタを行った理由として、1. 4文字未満のデータは少なく、この後議論する単語分割が出来ないようなデータ、それのみでは意味が通じないデータが多く含まれていたこと、2. 60字超過のデータは何らかの内容に対する説明と言った発話データとはややベクトルの異なるデータが多かったこと、深層学習を中心とした機械学習を用いた自然言語処理(要約タスクを除く)に用いるデータであると考えたとき、長すぎるテキストは短くされる前処理を施すことが一般的であること、を挙げる。
#+ATTR_LATEX: :caption \caption{発話データに対して適用したフィルタとその理由} :environment longtable :align |c|c|c|
|-------------------+------------+------------------------------------------------------------|
| フィルタの概要    | 詳細       | 理由                                                       |
|-------------------+------------+------------------------------------------------------------|
| Twitter特有の内容 | タグ       | 時系列で発生・消滅するため                                 |
|                   | 宛名       | 宛名のユーザに対する情報が必要であるため                   |
|                   | URLリンク  | リンクを発話として認めるべきか議論の余地があるため         |
|-------------------+------------+------------------------------------------------------------|
| 文字数            | 4文字未満  | データ数が少なかったため                                   |
|                   |            | 単語分割が出来ないため(極端な略語など)                     |
|                   | 60文字超過 | 発話データというよりは説明のようなデータが多かったため     |
|                   |            | 適用する予定の手法では情報の一部が切り落とされてしまうため |
|-------------------+------------+------------------------------------------------------------|
[fn:url-link] 勿論タグに意味が込められている例 (``#〇〇を許すな'' など) も多く見られたが、タグを認めるとタグのあるすべてのデータを手動で確認する必要があったため今回はすべて省いた。
**** abstract :noexport:
    　フィルタとして、タグや宛名、リンクを省いた後、4字以上、60字以下のデータを対象とした。その理由として、長文のツイートは説明の内容が含まれること、このデータの取扱先として深層学習を中心にした機械学習(要約タスクを除く)を想定しているため、あまり長すぎるテキストは切り落とす可能性があること、短すぎるつぶやきはリンクやタグのみのツイートが多かったことを挙げる。
*** 調査結果
フィルタによって抽出された 54,368 発話を調査した。\\
　まず発話データとして問題があると考えられる発話について報告する[fn:talk-report]。
#+ATTR_LATEX: :caption \caption{発話データの調査結果1} :environment longtable :align |c|c|c|
|----------------------------+----------------------------------------+---------------------------------|
| 概要                       | 詳細                                   | 例                              |
|----------------------------+----------------------------------------+---------------------------------|
| 他国語を用いた発話         | 中国語・英語等を用いた(含まれる)       | Very nice                       |
|                            | ツイートが 0.5 % 程度見られた          | Merry Christmas!                |
|                            |                                        | 謝謝                            |
|                            |                                        | Guten Morgen!                   |
|----------------------------+----------------------------------------+---------------------------------|
| テキストのみでは           | 画像などのコンテンツに                 | これ最高                        |
| 理解できない発話           | 対する発話が微量見られた               |                                 |
|                            |                                        |                                 |
|                            | ハイコンテクスト過ぎて                 | れ!!!                           |
|                            | 理解できないものが見られた             |                                 |
|----------------------------+----------------------------------------+---------------------------------|
| (意図的・意図的でない)誤字 |                                        | オフトゥン                      |
|                            |                                        | イケメソ                        |
|----------------------------+----------------------------------------+---------------------------------|
| 顔文字や絵文字の多用       | Twitterで許可されている絵文字や、      | $\verb#(*´ω`*)#$ お疲れ様です |
|                            | 顔文字が含まれる発話が 8% 程見られた   | $\verb#[(:3[■■]]#$            |
|                            |                                        | $\verb#(´∀`)>#$               |
|----------------------------+----------------------------------------+---------------------------------|
| 単語の一部や               | 特に感情的なつぶやきでは、             | 全全全休                        |
| 語尾の繰り返し             | 強調などの目的から                     | ほにゃほにゃほにゃほにゃする    |
|                            | 語の一部を繰り返す傾向が見られた       | やだぁあぁぁぁぁぁぁぁ!         |
|----------------------------+----------------------------------------+---------------------------------|
| 略語の多用                 | 長い単語、文は相互に理解できるような   | メリクリ!                       |
|                            | 形に省略されることが多かった           | なるはや                        |
|----------------------------+----------------------------------------+---------------------------------|
| 別の表現                   | 同じ意味を示すが                       | $\verb#!/!!!/！/！！/!!!!!!!!#$ |
|                            | 別の表記法があるものは                 | $\verb#・・・/…#$              |
|                            | 共通化されているわけではなかった       | こんど/今度                     |
|                            |                                        | 彼氏/カレ氏/カレシ              |
|                            |                                        | デス/です                       |
|----------------------------+----------------------------------------+---------------------------------|
| 伏せ字                     | 隠語など伏せ字を用いている場合があった | ○ね                            |
|----------------------------+----------------------------------------+---------------------------------|
| 語尾の特徴付け等           |                                        | ねれないぽよ                    |
|                            |                                        | ...と思うニョロ                 |
|                            |                                        | むいねー                        |
|----------------------------+----------------------------------------+---------------------------------|

　次に主に情報の価値として問題があると考えられる発話について報告する。
#+ATTR_LATEX: :caption \caption{発話データの調査結果2} :environment longtable :align |c|c|c|
|----------------------+---------------------------------------------+------------------------------|
| 概要                 | 詳細                                        | 例                           |
|----------------------+---------------------------------------------+------------------------------|
| 個人情報の入ったもの | 電話番号やSNSのIDなどを                     |                              |
|                      | 含まれるものが、                            |                              |
|                      | 一万件に対して5,6件あった                   |                              |
|                      |                                             |                              |
|                      | 個人名・アカウント名が含まれるものを        |                              |
|                      | 含めると5%程になってしまった                |                              |
|----------------------+---------------------------------------------+------------------------------|
| 時刻など             |                                             | 2018.12.26 06:00             |
|----------------------+---------------------------------------------+------------------------------|
| 頻度が高すぎるもの   | 挨拶等                                      | メリクリ！                   |
|                      |                                             | おはよう                     |
|----------------------+---------------------------------------------+------------------------------|
| センシティブなもの   |                                             |                              |
|----------------------+---------------------------------------------+------------------------------|
| Twitter特有のもの    |                                             | 凍結された                   |
|                      |                                             | フォローありがとうございます |
|----------------------+---------------------------------------------+------------------------------|
| 数値データ           | 英語でのNLPの一部では積極的に削除されている | 2018                         |
|                      |                                             | 200円                        |
|                      | 漢数字                                      | 一                           |
|                      | ギリシャ数字                                | V                            |
|                      |                                             |                              |
|----------------------+---------------------------------------------+------------------------------|
　最後にこの後実験として取り上げる極性判定のデータとして問題があると考えられる発話について報告する。
#+ATTR_LATEX: :caption \caption{発話データの調査結果3} :environment longtable :align |c|c|c|
|----------------------+------------------------------------+-----------------------------------|
| 概要                 | 詳細                               | 例                                |
|----------------------+------------------------------------+-----------------------------------|
| 予定などのメモ書き   | 個人の予定や                       |                                   |
|                      | イベントの告知                     |                                   |
|----------------------+------------------------------------+-----------------------------------|
| 企業などの広告       |                                    |                                   |
|----------------------+------------------------------------+-----------------------------------|
| 取引などのツイート   |                                    | 買)鳥獣戯画のペンダント           |
|----------------------+------------------------------------+-----------------------------------|
| 豆知識や引用         | 特に深夜〜早朝にかけては           | 丁字染ちょうじぞめ                |
|                      | 自動ツイートのような形式の         | オロバス ￥n ソロモン72柱の…      |
|                      | 豆知識や引用の頻度が高くなっていた | [飲み会で使える？ダジャレ]…       |
|                      | 最大では3％程がこれに含まれていた  | サーッ!(迫真)                     |
|----------------------+------------------------------------+-----------------------------------|
| 感情が含まれているか |                                    | なぜ僕らは生きるのか              |
| 疑問のあるデータ     |                                    |                                   |
|----------------------+------------------------------------+-----------------------------------|

[fn:talk-report] すべての報告における例は、個人情報を含んだ部分を含まないように編集されている。
*** 考察
データを収集した時間も相まって広告や豆知識・引用といった発話が多く観測された。これらのデータは極性判定やカテゴリ分類、ユーザクラスタリングなどに悪影響を与えることが論理的に考えられる。予定や広告、時刻などに関係したデータは、ほとんどの場合で一過性のものであるため長期的なシステムのためのデータとして見たときには適切であるか疑問が残る。\\
　数値データや個人名のようなデータに関しては、英語でのNLP、特に良い精度を持ったいくつかのタスクに対しては何らかの記号に置換されることが多い。しかし日本語でこれを適用しようとしたとき、1. 様々な表記方法があること、2. スペースで分割されていないため、形態素解析などの技術やNER(Named Entity Recognition 固有表現抽出)の技術を組み合わせなければ抽出できないこと、が問題として挙げられる。特に形態素解析に関してはTwitterのデータのような正規化されていないテキストに行った場合、精度が比較的に落ちるため、何らかの精度向上手法または別手法を提案する必要がある。\\
　また同じ意味を表す文でも様々なバリエーションがあることがわかった。例えば``おはよう''を例に取ってみると、``おはようございます''、``おはよー''、``おは''、``おはよおおお''、``おは(愛称等)''といったバリエーションが見られた。これらはキャラクタ性を持たせるためには必要な分散であるが、意味のみに注目した場合や、語彙数の問題を考慮した場合には極力減らされたほうが良いと考えられる[fn:decrease-vocab]。更にバリエーションのある文は平均的に出現頻度が高い[fn:sent-freq]ため、これを集めすぎるとデータに偏りが生まれてしまうことも考慮する必要があるだろう。\\
　極性判定のみに絞った議論をするならば、例えば自動ツイートされた発話にはユーザの極性があるとは考えにくいため、これを省くのが適当であると考えられる。しかし以上のことを踏まえてデータの再抽出・編集をフィルタリング後のデータの中の、15,000程度のデータに対して行ったところ、1,500程度のデータしか得られなかった[fn:gather-sent-data]。
\begin{itembox}[l]{形態素解析で成功した例}
りかちゃんありがとう\\

<形態素解析結果>\\
りか 名詞,固有名詞,人名,名,*,*,りか,リカ,リカ \\
ちゃん 名詞,接尾,人名,*,*,*,ちゃん,チャン,チャン\\ 
ありがとう 感動詞,*,*,*,*,*,ありがとう,アリガトウ,アリガトー
\end{itembox}

\begin{itembox}[l]{形態素解析で失敗した例}
山さんに・・・\\

<形態素解析結果>\\
山 名詞,一般,*,*,*,*,山,ヤマ,ヤマ \\
さん 名詞,接尾,人名,*,*,*,さん,サン,サン\\
に 助詞,格助詞,一般,*,*,*,に,ニ,ニ\\
・・・\\

※人名を指すが一般名詞として認識されてしまっている。\\
このよう場合には単語分割した後、NERを用いて検出することが望ましいと言える。
\end{itembox}
[fn:decrease-vocab] 英語の NLP (例えば機械翻訳) でも前処理として、``he's'' を  ``he is'' にするなどの前処理が行われることがある。
[fn:sent-freq] 例えば26日午前6時ちょうど頃は3割程度が宛先や顔文字などの付加情報の差はあれど``おはよう''の意味の発話であった。
[fn:gather-sent-data] これは公開できる形にするため、個人情報を含んだデータを編集・削除したこと、極性を持たないと思われるデータ(中性という意味ではない)を省いたこが大きく起因している。
*** abstract :noexport:
　調査結果を表を用いて示す。そして後述の実験である極性判定実験のために抽出できたデータが10%程度であったことを説明する。

** 調査) 対話データ
対話データとして、2018年8月から12月にかけて不定期にTwitterから収集した対話データ、一般公開されている書き起こしの対話コーパス、一般公開されているチャットの対話コーパスについてデータを観測した。\\
　以下に調査結果として何らかの問題があると考えられる特徴について報告し、それに対する考察を述べる。
*** 調査結果
**** Twitterから収集した対話データ
\\
　収集方法は Twitter 社が公開している API を用い、日本のユーザから呟かれている内容の中から、3発話以上対話が続いているものを収集した。この処理によって生データが 10,767 の対話ペアが得られた。そして生データに対しては [[#filter]] と同様にハッシュタグと宛名、そしてURLリンクを削除したが、文字制限は対話間の意味を観測するため行わなかった。
#+ATTR_LATEX: :caption \caption{対話データの調査結果1} :environment longtable :align |c|c|c|
|--------------------------------+-------------------------------------------+-----------------------|
| 概要                           | 詳細                                      | 例                    |
|--------------------------------+-------------------------------------------+-----------------------|
| センシティブな内容             | 3％程はセンシティブな内容の対話であった。 |                       |
|--------------------------------+-------------------------------------------+-----------------------|
| ゲームに関する内容             | 5％程はゲームに関する内容であった。       |                       |
|                                | その中には一過性の内容                    |                       |
|                                | (情報共有や待ち合わせ等)が含まれていた    |                       |
|--------------------------------+-------------------------------------------+-----------------------|
| 顔文字や絵文字等が含まれるもの | 15％程は顔文字や絵文字を含んでいた        | おはよーございます!   |
|                                |                                           | $\verb#((*゜д゜)ノ#$ |
|                                |                                           |                       |
|                                | そのうちの2割ほどは顔文字・絵文字のみが   | $\verb#('д`)#$       |
|                                | 発話になっているものがあった              |                       |
|--------------------------------+-------------------------------------------+-----------------------|
| 似たような内容                 | 特に挨拶など同じような                    | おはようございますよ  |
|                                | 内容の対話頻度が高かった                  |                       |
|                                | 朝方には半数が                            |                       |
|                                | ``おはようございます''の内容であった      |                       |
|--------------------------------+-------------------------------------------+-----------------------|
| 事前知識を必要とする内容       | 間柄や話題(例えばゲーム)の内容に          | lineカメラたのしい    |
|                                | 関する事前知識がいるものが                |                       |
|                                | 多く感じられた。[fn:pre-knowledge]        |                       |
|--------------------------------+-------------------------------------------+-----------------------|
| 固有表現が含まれるもの         | 名前等固有表現が含まれるものは            |                       |
|                                | 3割程度であった。                         |                       |
|--------------------------------+-------------------------------------------+-----------------------|


[fn:pre-knowledge] アノテータが一人のため境界を判定することは難しいため、割合を明言することは出来ない。
**** 名大会話コーパスから収集したデータ
\\
　名大会話コーパス(\cite{meidai}) から入手できる129会話について観測した。名大会話コーパスとは日本語母語話者同士の雑談を文字化したコーパスで、129会話を収録、その合計時間は100時間に及ぶ比較的大規模なものだ。ライセンスがクリエイティブ・コモンズ表示-非営利-改変禁止 4.0 国際ライセンスで公開されているため、研究目的で用いることが非常に容易なコーパスであると言える。\\
　非常に大規模かつ考察で述べるように複雑な内容であるため、出現頻度については言及しない。

#+ATTR_LATEX: :caption \caption{対話データの調査結果2} :environment longtable :align |c|c|c|
|--------------------------+--------------------------------+----------------------------------------------|
| 概要                     | 詳細                           | 例                                           |
|--------------------------+--------------------------------+----------------------------------------------|
| 言外のコミュニケーション | 言語化せずに伝える内容があった | ＜笑い＞(共感の意)                           |
|--------------------------+--------------------------------+----------------------------------------------|
| 長文や複文               | 相手が内容を理解したものとして | すごい勢いで走って。                         |
|                          | 文を継続させる場合があった。   | 私、あ、あーさっきの犬だとか                 |
|                          |                                | 私たちが言っとるじゃん。                     |
|                          |                                | 犬も気がついたじゃん。                       |
|                          |                                | じゃははって走ってきちゃって、犬が。         |
|--------------------------+--------------------------------+----------------------------------------------|
| 書き言葉・話し言葉の変化 | あの $\rightarrow$ あん        | ほいでさあ、ずっと歩いていたんだけど、       |
|                          | といった変化が見られた。       | そうすと上から、なんか町の中が見れるじゃん。 |
|--------------------------+--------------------------------+----------------------------------------------|
| 固有表現                 | 個人情報保護のため             | ＊＊＊の町というのはちいちゃくって ...       |
|                          | 名前などの                     | ほいで、あの、F023さんはあたしが前の日に...  |
|                          | 固有表現は置換されていた       | Ｃが、あのー、写真を見せてくれたんだけど...  |
|--------------------------+--------------------------------+----------------------------------------------|

**** 対話破綻チャレンジ2から収集したデータ
\\
　対話破綻チャレンジとは人間と対話システムとの間で生じる「対話破綻」(ユーザが対話を継続できなくなる状態) を自動検出することを目的とした、評価型ワークショップである。\\
　このデータは対話システムと人間間とのテキストを用いた対話データと、その対話が成立しているかどうかを判定した複数人によるアノテーションが含まれており、本研究の目指すエージェントと人の対話の形に最も近いデータセットであると言える。\\
　本データセットは問題点が少なく、アノテーションに従って、比較的成立しているとみなされた対話を抽出することで対話データを生成することが出来た。
*** 考察
Twitterから収集した対話データに関してはTwitterデータとして非常に有効であると考えられる。しかし比較的にセンシティブな内容が多く、これを対話データとして学習させてしまうことによる、対話システムの倫理的な問題を考慮しなければならないだろう。また顔文字や絵文字等は [[調査) 発話データ]] で考察したように単位で分割することが難しい。同様に同じような意味を持った対話が多く存在していたことから、これにも対処する必要があるだろう。\\
　名大会話コーパスから収集したデータに関しては日常会話を分析・理解するには抽出するには非常に価値のあるデータセットであるが、これをチャットのようなテキスト入力等を介した対話には不適切なデータであると考えられる。このコーパスを観測して考察できる内容としては、1.書き言葉・話し言葉の変化は想像以上に大きなものであったと言えること、2.決して発話一つに対して返答が一つという形式になっているわけではないこと、3.固有表現の取扱についてより深く考察する必要があること、であった。\\
　対話破綻チャレンジ2から収集したデータはほぼ申し分ない自然さを持ったデータを集めることができることがわかった。しかし対話システムと人との対話データであるため、``人対人のような日常会話''対話は比較的少なく、``人のような''対話エージェントを作成するならば、不足している対話を外部から付け加える必要があると考えられる。
*** abstract :noexport:
 　対話データとして、Twitterのデータ、一般公開されている書き起こしの対話コーパスの内容について言及し、前者に比べ後者は文字だけでは学習することが難しい(背景知識が必要である)ことを説明する。
** 問題設定
NLP の研究分野の一つについて単語分散を用いた言語モデル生成がある。単語といったある単位ごとの意味をベクトルなどの数値にする手法であり、この利点としては、単位ごとの距離を考えたとき、意味的に近い要素は近く、遠い要素は遠くなることで様々な NLP のタスクで自然言語を数値化する際に、自然言語の特徴を強く表すことができるようになるというものがある。\\
　本研究ではこの単語分散を得るという問題に対してデータの前処理がどのように影響するのかを理解する目的で、2つの実験を行う。\\
　一つは、1.漢字・かな入り混じり文、2.かな飲みに変換した文、によって得られる単語分散の性質の違いを確認する実験、もう一つは得られた単語分散を用いて極性判定を行う実験である。\\
TODO: Word Embedding で得られるT-SNE画像を挿入する
*** next :noexport:
　もう一つは、同様の2つのデータに対して、文字ベースで単語分散を得る手法である、Contextual String Embedding for Sequence Labeling の言語モデル生成を用い、クラス分類を行う実験。
*** abstract :noexport:
英語では単語分散を得るために space で区切られた単語ごとに id を振る手法が有名であったが、最近では単語の一部 subword を用いる手法が出てきている。その例として google の出した wordpiece があることを紹介する。
　(単語分散を得る際に、日本語は英語と違って、単語ごとに分割されていないことを上げ、WordPirce SentencePiece 単語分割を用いる手法があることを紹介し、最近では単語分散を得ることのできる有力な手法としてELMo、 BERT が台頭してきたことを紹介し、そこでは SentencePiece が有力であるという実験結果が出ていることを示す。)
　今回は単語分割+subwordを用いることを想定し、1. fasttext の skipgram を用いて漢字かな入り混じり、かなのみのテキストに対して語彙数、損失、ある単語の類似語について実験をすること 2. 得られた単語分散を用いて極性判定の実験をすることを説明する。
*** 関連研究
単語分散を得るための手法としては、SVD(特異値分解)(TODO:svd)やWord2Vec(TODO:word2vec)やglove(TODO:glove)、fasttext(TODO::fasttext)といった手法が有名だ。また昨今、NLPでは文単位での解析が多いこと、文全体の意味も考慮したほうが良いというモチベーションから、単語分散のみならず、文ごとの関係も考慮してベクトルを生成する手法が提案されている。その代表例が、ELMo(TODO:ELMo)、BERT(TODO:BERT)と言った深層学習のモデルであり、昨今の様々なNLPのタスクでSOTAを達成している。
** 実験) 漢字かな問題に対する単語分散取得
　この実験では、日本語特有に存在する``漢字とかなによる同意表現の複数表記''を解消するための漢字 $\rightarrow$ かな変換を行い、
*** 実験概要
    単語分散を得るためのコーパスとしてWikipediaコーパスを用いたことなど、実験の概要を示す。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
** 実験) 得られた単語分散を用いた極性判定
*** 実験概要
    [[実験) 漢字かな問題に対する単語分散取得]] で得た単語分散を用いて極性判定を行ったこと、極性判定のデータセットは [[調査) 発話データ]] で抽出・編集したデータであることを示す。(抽出・編集条件 を再度示す)
　　また実験に用いたネットワークについて説明する (CNN-RNN)
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 文抽出を念頭においた不均衡分散・サイズの分類問題
:PROPERTIES:
:CUSTOM_ID: inbalance-categorization
:END:

** 問題設定
   入力された文が特定の意味を持った文であるかどうかを抽出する問題において、どのように分類するべきなのかを検討する。
   一般的なクラス分類との比較として、この問題は特定の意味を持った文の集合であるクラスと、それ以外のクラスとでデータの分散やデータの数に大きな差があること、画像認識と違ってアップサンプリング(水増し)が難しいことを問題点としてあげ、まず一般的に用いられている分類問題として解き、次に提案する手法である点類似度を用いたクラス分類を説明する。
   (特定の文で分岐を行い、その組み合わせを用いてユーザとの対話を試みる、シナリオ型対話システムがあることにも触れる。)
   考察は比較のためにすべての実験のあとにまとめることを説明する。
** 実験) 自然言語処理の場合における一般的なクラス分類
   news20 というデータセットを用いてCNNを用いた1クラス分類(1カテゴリ：19カテゴリ)を行う。相手のクラスの分散が想定よりも小さいことを注記する。
** 実験) 画像タスクに置換した場合における一般的なクラス分類
   imagenet の画像タスクで、猫・犬分類と猫・ランダム画像でのクラス分類を行う。
** 実験) 自然言語処理の場合における点類似度を用いたクラス分類
   BERTモデルを用いて、文類似度を測り、それを用いてクラス分類を行う。
** 実験) 画像タスクに置換した場合における点類似度を用いたクラス分類
   画像の類似度を測り、それを用いてクラス分類を行う(実験が間に合えば)
** 考察
   後者のほうが拡張性があること、前者の場合に猫・犬よりも猫・ランダムのほうが精度が悪くなる傾向があることを指摘する。
* 機械翻訳システムを用いた対話モデル
:PROPERTIES:
:CUSTOM_ID: con-model-use-mt
:END:

** 問題設定
   　反射応答のような問題について、機械翻訳を用いて発話を行わせることを提案、その手法として昨今機械翻訳の分野でSOTAを取っていたTransformerを用いることを実験し、その性能を考察する。
** 実験) Seq2Seq Attention と Transformer の精度比較
*** 実験概要
    データセットなどの実験概要を示す
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 文のスタイル変換
:PROPERTIES:
:CUSTOM_ID: style-transfer
:END:

** 関連研究
   この分野の関連研究として seqence to better sequence(本実験)や、(夏季レポートに記載したもの)　を例に挙げる。(画像認識の分野におけるスタイル変換についても触れておく必要があれば触れておく)
** 問題設定
   書き言葉→話し言葉変換を行うことなどを説明する。またこの実験における話し言葉、書き言葉の定義についても言及しておく。
** 実験) 書き言葉→話し言葉のスタイル変換
*** 実験概要
    データセット、モデルの説明を行う。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* CoLAタスクを応用した対話システムのエラー検知
:PROPERTIES:
:CUSTOM_ID: cola-error-handling
:END:

** 問題設定
   　深層学習を用いた対話モデルや、文生成のモデルを用いる際に出てしまう可能性のある不自然な文を検出するという問題設定について説明する。
** 実験) 対話システムのエラー検知
*** 実験概要
    　BERTを用いて実験したことを示す。
    　(このモデルを作成するにあたり文の自然さを評価するための CoLA タスクというものに注目し、これを解いている BERT と呼ばれるモデルを用いる。)
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 付録
  この付録の存在意義について説明する。(論文の補足であることを説明する)
** 対話システムの関連研究
:PROPERTIES:
:CUSTOM_ID: extra_rsearch
:END:
この章では [[#relation-reserch]] で引用した対話システムのうち、 Sounding Board と Gunrock について詳細な説明を行う。りんなに関しては非公開情報が多いため説明を省略する。
*** Sounding Board
 Sounding Board \cite{1804.10202}
*** Gunrock
Gunrock \cite{Gunrock}
** 日本語データの取り扱いについて
*** 単語分割
    単語分割
*** 形態素解析
*** NER
*** Word Piece
    Word Piece
*** Sentence Pieces
    Sentence Pieces
*** Skipgram
    Skipgram
*** CNN-RNN
    CNN-RNN
*** 名大会話コーパスのデータ例 :noexport:
以下に名大会話コーパス(\cite{meidai})のデータ例を示す。
#+begin_quote
＠データ１（約３５分）\\
＠収集年月日：２００１年１０月１６日\\
＠場所：ファミリーレストラン\\
＠参加者F107：女性３０代後半、愛知県幡豆郡出身、愛知県幡豆郡在住\\
＠参加者F023：女性４０代後半、岐阜県出身、愛知県幡豆郡在住\\
＠参加者M023：男性２０代前半、愛知県西尾市出身、西尾市在住\\
＠参加者F128：女性２０代前半、愛知県西尾市出身、西尾市在住\\
＠参加者の関係：英会話教室の友人\\
F107：＊＊＊の町というのはちいちゃくって、城壁がこう町全体をぐるっと回ってて、それが城壁の上を歩いても１時間ぐらいですよね。\\
F023：１時間かからないぐらいだね。\\
４、５０分で。\\
F107：そうそう。\\
ほいでさあ、ずっと歩いていたんだけど、そうすと上から、なんか町の中が見れるじゃん。\\
あるよね。\\
ほいでさあ、なんか途中でワンちゃんに会ったんだね。\\
（ふーん）散歩をしてるワンちゃんに会ったんだ。\\
F023：城壁の上をやっぱ観光客なんだけどワンちゃん連れてきてる人たち結構多くて。\\
F107：で、こう、そのワンちゃんと２人を、なに、お父さんとお母さんと歩いて、ワンちゃんに会ったんだ。\\
途中で。\\
あワンちゃーんとか言ってなでて、ほいで、この人たちはこっち行って、あたしらこっち行ったじゃん。\\
ずうーとこうやって回ってきてるの。\\
また会っちゃって。\\
ここで。\\
そうしたら。\\
F128：おー、そら地球はやっぱり丸かったみたいだね。\\
F107：そうしたらそのワンちゃんがなんかか喜んじゃって、で、あたしの方に走ってきて、とびついてきちゃってさ。\\
別にあたしさあ、別にさっきなでただけなのにさあ、なんかすごーいなつかれちゃってね。\\
F023：さっきね、別に、そんなになでてもいないんだよ。\\
F107：よしよしって言っただけなのに。\\
F023：あらワンちゃんだーとか言ってすれ違ったんだよ。\\
普通に。\\
それでその次のとき、向こうの方からはーっといってかけてくるじゃん。\\
F107：すごい勢いで走って。\\
私、あ、あーさっきの犬だとか私たちが言っとるじゃん。\\
あんで向こうの人たちも、あっ、さっき会った子たちねみたいな感じで気がついたじゃん。\\
犬も気がついたじゃん。\\
じゃははって走ってきちゃって、犬が。\\
Ｘ：＜笑い＞そうなんだ。\\
＜笑い＞\\
F107：ほいであちしなんかとびつかれちゃったよ。\\
Ｘ：うそ。\\
＜笑い＞\\
F023：＊＊＊って言ってさ。\\
F107：さっきちょっとなでただけなのにって。\\
かわいかったね。\\
...
#+end_quote
** 質問文抽出を念頭においた不均衡分散・サイズの分類問題
*** 画像データ
    画像データ
*** 文データ
    文データ
** 機械翻訳システムを用いた対話
*** Seq2Seq Attention
    Seq2Seq Attention
*** Transformer
    Transformer
** 文のスタイル変換
*** Sequence to Better Sequence
    Sequence to Better Sequence
*** CopyNet
    CopyNet
*** Denoising Auto Encoder
    Denoising Auto Encoder
** CoLAタスクを応用した対話システムのエラー検知
*** BERT
    BERT
* 結論
** 今後の課題
   今回できなかった文生成の問題・論文に載せることのできなかった推論の内部状態の更新等について言及する。また精度向上や今後取り組みたい問題設定(Unityなどで仮想世界を作り、その中で対話を行えるようにするエージェント作成したい旨)について話す。
#+LATEX: \newpage
#+LATEX: \printbibliography

* C++ コードをEmacs + Org mode で書く
#+CAPTION: テストコード
#+header: :includes <iostream>
#+header: :var greet="Hello World"
#+begin_src C++ :exports both :results latex :cache yes
std::cout << greet << std::endl;
#+end_src

#+RESULTS[72a19f4e33f7ff6180eab6e0536194c82f003d2c]:
#+BEGIN_EXPORT latex
Hello World
#+END_EXPORT

#+CAPTION: init.el
#+BEGIN_SRC emacs-lisp

(setq org-latex-listings 'minted
      org-latex-packages-alist '(("" "minted")))

(require 'org)
(require 'ox-latex)
(require 'ox-bibtex)
(require 'org-ref)

(setq org-latex-toc-command 
"\\pagenumbering{roman} \\tableofcontents
 \\clearpage \\listoffigures \\clearpage")

(setq org-format-latex-options 
  (plist-put org-format-latex-options :scale 2.0))

(setq bibtex-completion-pdf-open-function 'org-open-file)

(setq org-latex-listings 'minted)

(setq org-latex-minted-options
      '(("frame" "lines") ("linenos=ture")
        ("obeytabs") ("tabsize=4")))

(setq org-latex-pdf-process
      '("platex --shell-escape --kanji=utf-8 %f"
        "platex --shell-escape --kanji=utf-8 %f" 
        "biber %b"
        "platex --shell-escape --kanji=utf-8 %f" 
        "dvipdfmx %b"))


(org-babel-do-load-languages
 'org-babel-load-languages
 '((C . t)))
#+END_SRC

#+CAPTION: 書き方
#+BEGIN_SRC text
#+CAPTION: テストコード
#+header: :includes <iostream>
#+header: :var greet="Hello World"
,#+begin_src C++ :exports both :results latex :cache yes
std::cout << greet << std::endl;
,#+end_src

#+RESULTS[72a19f4e33f7ff6180eab6e0536194c82f003d2c]:
,#+BEGIN_EXPORT latex
Hello World
,#+END_EXPORT
#+END_SRC








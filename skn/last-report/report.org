#+TITLE: モジュール分割された日本語対話システムの研究
#+SUBTITLE: 
#+AUTHOR: 
# This is a Bibtex reference
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil arch:headline ^:nil
#+OPTIONS: author:nil broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:nil e:nil email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:nil title:nil toc:t todo:t |:t
#+LANGUAGE: ja
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 26.1 (Org mode 9.1.4)
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, 10pt, dvipdfmx]
#+LATEX_HEADER: \usepackage{amsmath, amssymb, bm}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage{pxjahyper}
#+LATEX_HEADER: \hypersetup{colorlinks=false, pdfborder={0 0 0}}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[backend=biber, bibencoding=utf8]{biblatex}
#+LATEX_HEADER: \usepackage[top=30truemm, bottom=30truemm, left=25truemm, right=25truemm]{geometry}
#+LATEX_HEADER: \addbibresource{reference.bib}
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP: indent overview inlineimages


* 序論
#+LATEX: \pagenumbering{arabic}
** 研究背景及び目的
  　まず受付やオンラインチャットなどにおいて対話システムの需要が増えていること、Amazon AlexaやSiriなどを例に出して説明する。次にキャラクタ性を持ったマルチモーダル対話システムとして、りんなを例に上げる。
  　その実装例として、Amazon Alexa Prize のコンテストを例に出す。
  　本研究の目的として、日本語環境下で、りんなのような機能を持つシステムを構築すること、ゲームAIへの転用などを視野にいれていることを説明する。そしてシステムの概要として、対話システムという大問題に対して、いくつかの小問題に分割し、それらを組み合わせるモジュール分割という手法を用いることにしたことを説明する。
** 本論文の構成
   　1章として論文の導入をしていること。2章で対話システムの関連研究として1章の研究背景で紹介した(Amazon Alexa Prizeやりんな)の概要を説明していること。3章として対話システム全体の実装として目標としている構成図を示していること。4章については日本語のデータをどのように扱うべきか考察したこと。5章から8章にかけてはそれぞれのモジュールに対する研究について説明をしていること。9章に対してはそれぞれの章で説明が不足しているであろう内容を補足するための付録であること。を説明する。
* 対話システムの関連研究
  　関連研究として、Amazon Alexa Prizeの問題設定の説明、 2018 年、2017年の最優秀賞団体がモジュール分割して問題を解決したことを説明する。りんなの概要についても紹介する。
* 想定する対話システムの全体像
  　全体像図のグラフを示す。
  　それぞれの問題をリストとして示す。
* 日本語データの取り扱いについて
  　日本語データは英語データに比べていくつかの問題があること。その例として。語尾の多彩な変化や漢字かな問題があることを紹介する。また一般に公開されている対話データセットをどのように用いるべきなのかについての考察を行ったこと、漢字かな問題に対して単語分散を得るための手法を二種類想定し、それぞれの性質を比較する。
** 調査) 発話データ
   　発話データとして、2018年12月25日 23:00頃 から翌 26日 10:00頃 までに収集した7万件のTwitterデータを収集し、その性質を観測した。
*** フィルタ
    　フィルタとして、タグや宛名、リンクを省いた後、4字以上、60字以下のデータを対象とした。その理由として、長文のツイートは説明の内容が含まれること、このデータの取扱先として深層学習を中心にした機械学習(要約タスクを除く)を想定しているため、あまり長すぎるテキストは切り落とす可能性があること、短すぎるつぶやきはリンクやタグのみのツイートが多かったことを挙げる。
*** 調査結果
    　調査結果を表を用いて示す。そして後述の実験である極性判定実験のために抽出できたデータが10%程度であったことを説明する。
** 調査) 対話データ
   　対話データとして、Twitterのデータ、一般公開されている書き起こしの対話コーパスの内容について言及し、前者に比べ後者は文字だけでは学習することが難しい(背景知識が必要である)ことを説明する。
** 問題設定
   　英語では単語分散を得るために space で区切られた単語ごとに id を振る手法が有名であったが、最近では単語の一部 subword を用いる手法が出てきている。その例として google の出した wordpiece があることを紹介する。
   　(単語分散を得る際に、日本語は英語と違って、単語ごとに分割されていないことを上げ、WordPirce SentencePiece 単語分割を用いる手法があることを紹介し、最近では単語分散を得ることのできる有力な手法としてELMo、 BERT が台頭してきたことを紹介し、そこでは SentencePiece が有力であるという実験結果が出ていることを示す。)
   　今回は単語分割+subwordを用いることを想定し、1. fasttext の skipgram を用いて漢字かな入り混じり、かなのみのテキストに対して語彙数、損失、ある単語の類似語について実験をすること 2. 得られた単語分散を用いて極性判定の実験をすることを説明する。
** 実験) 漢字かな問題に対する単語分散取得
*** 実験概要   
    単語分散を得るためのコーパスとしてWikipediaコーパスを用いたことなど、実験の概要を示す。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
** 実験) 得られた単語分散を用いた極性判定
*** 実験概要
    [[実験) 漢字かな問題に対する単語分散取得]] で得た単語分散を用いて極性判定を行ったこと、極性判定のデータセットは [[調査) 発話データ]] で抽出・編集したデータであることを示す。(抽出・編集条件 を再度示す)
　　また実験に用いたネットワークについて説明する (CNN-RNN)
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 文抽出を念頭においた不均衡分散・サイズの分類問題
** 問題設定
   入力された文が特定の意味を持った文であるかどうかを抽出する問題において、どのように分類するべきなのかを検討する。
   一般的なクラス分類との比較として、この問題は特定の意味を持った文章の集合であるクラスと、それ以外のクラスとでデータの分散やデータの数に大きな差があること、画像認識と違ってアップサンプリング(水増し)が難しいことを問題点としてあげ、まず一般的に用いられている分類問題として解き、次に提案する手法である点類似度を用いたクラス分類を説明する。
   (特定の文章で分岐を行い、その組み合わせを用いてユーザとの対話を試みる、シナリオ型対話システムがあることにも触れる。)
   考察は比較のためにすべての実験のあとにまとめることを説明する。
** 実験) 自然言語処理の場合における一般的なクラス分類
   news20 というデータセットを用いてCNNを用いた1クラス分類(1カテゴリ：19カテゴリ)を行う。相手のクラスの分散が想定よりも小さいことを注記する。
** 実験) 画像タスクに置換した場合における一般的なクラス分類
   imagenet の画像タスクで、猫・犬分類と猫・ランダム画像でのクラス分類を行う。
** 実験) 自然言語処理の場合における点類似度を用いたクラス分類
   BERTモデルを用いて、文章類似度を測り、それを用いてクラス分類を行う。
** 実験) 画像タスクに置換した場合における点類似度を用いたクラス分類
   画像の類似度を測り、それを用いてクラス分類を行う(実験が間に合えば)
** 考察
   後者のほうが拡張性があること、前者の場合に猫・犬よりも猫・ランダムのほうが精度が悪くなる傾向があることを指摘する。
* 機械翻訳システムを用いた対話
** 問題設定
   　反射応答のような問題について、機械翻訳を用いて発話を行わせることを提案、その手法として昨今機械翻訳の分野でSOTAを取っていたTransformerを用いることを実験し、その性能を考察する。
** 実験) Seq2Seq Attention と Transformer の精度比較
*** 実験概要
    データセットなどの実験概要を示す
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 文章のスタイル変換
** 関連研究
   この分野の関連研究として seqence to better sequence(本実験)や、(夏季レポートに記載したもの)　を例に挙げる。(画像認識の分野におけるスタイル変換についても触れておく必要があれば触れておく)
** 問題設定
   書き言葉→話し言葉変換を行うことなどを説明する。またこの実験における話し言葉、書き言葉の定義についても言及しておく。
** 実験) 書き言葉→話し言葉のスタイル変換
*** 実験概要
    データセット、モデルの説明を行う。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* CoLAタスクを応用した対話システムのエラー検知
** 問題設定
   　深層学習を用いた対話モデルや、文生成のモデルを用いる際に出てしまう可能性のある不自然な文章を検出するという問題設定について説明する。
** 実験) 対話システムのエラー検知
*** 実験概要
    　BERTを用いて実験したことを示す。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 付録
  この付録の存在意義について説明する。(論文の補足であることを説明する)
** 対話システムの関連研究
*** Sounding Board
    　Sounding Board
*** 2018 年の Amazon Alexa Prize
    Amazon Alexa Prize
** 日本語データの取り扱いについて
*** 単語分割
    単語分割
*** Word Piece
    Word Piece
*** Sentence Pieces
    Sentence Pieces
*** Skipgram
    Skipgram
*** CNN-RNN
    CNN-RNN
** 質問文抽出を念頭においた不均衡分散・サイズの分類問題
*** 画像データ
    画像データ
*** 文データ
    文データ
** 機械翻訳システムを用いた対話
*** Seq2Seq Attention
    Seq2Seq Attention
*** Transformer
    Transformer
** 文章のスタイル変換
*** Sequence to Better Sequence
    Sequence to Better Sequence
*** CopyNet
    CopyNet
*** Denoising Auto Encoder
    Denoising Auto Encoder
** CoLAタスクを応用した対話システムのエラー検知
*** BERT
    BERT
* 結論
** 今後の課題
   今回できなかった文生成の問題・論文に載せることのできなかった推論の内部状態の更新等について言及する。また精度向上や今後取り組みたい問題設定(Unityなどで仮想世界を作り、その中で対話を行えるようにするエージェント作成したい旨)について話す。

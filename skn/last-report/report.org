#+TITLE: モジュール分割された日本語対話システムの研究
#+SUBTITLE: 
#+AUTHOR: 
# This is a Bibtex reference
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:t arch:headline ^:nil
#+OPTIONS: author:nil broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:nil e:nil email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:nil title:nil toc:t todo:t |:t
#+LANGUAGE: ja
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 26.1 (Org mode 9.1.4)
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, dvipdfmx]
#+LATEX_HEADER: \usepackage{amsmath, amssymb, bm}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage{pxjahyper}
#+LATEX_HEADER: \hypersetup{colorlinks=false, pdfborder={0 0 0}}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[backend=biber, bibencoding=utf8, style=authoryear]{biblatex}
#+LATEX_HEADER: \usepackage[top=30truemm, bottom=30truemm, left=25truemm, right=25truemm]{geometry}
#+LATEX_HEADER: \addbibresource{reference.bib}
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP: indent overview inlineimages


* 序論
#+LATEX: \pagenumbering{arabic}
** 研究背景及び目的
   ある目的に対してより完璧に(accuracyが高くなるように)命令を実行をする Artificial Intelligence が求められている昨今のAI競争の時代に対し、自然言語処理やゲームAIのようなタスクは極めて複雑な課題を抱えている。例えばそれは``言葉''という問題である。これは人間がコンピュータに正解となるものを提供することが極めて難しく、``なんとなく良い感じに''目的を達成してくれることを期待することが多い。この問題に対処するための手段として、入手でき得る限りの大規模なデータを用意して中心極限定理的に尤もらしい中心部を得る方法や、とにかく何らかの単一のモデルに押し込めて問題を解くという方法 [fn:hred] がある。それに対して、データそのものを一旦精査・前処理すること、問題を整理・分解しそれぞれを解くことも研究 [fn:multimordule] として存在している。
   　自然言語処理の、特に対話システムについて考えたとき、小問題に分割した上で対話システムを達成した例として、例として Amazon Alexa Prize [fn:alexaprize] というコンテストやMicrosoft社が研究・開発している``りんな'' [fn:rinna] を挙げることができる。これらは対話を行うという問題に対して小さな部分問題を解くタスクを設定し、それぞれを組み合わせることで元の問題を解くというスタイルを取っている。
   　本研究ではこれらを参考に、日本語の対話システムを作成するという問題に対して小問題を設定しそれを解くための手法を提案・実験する。またその前準備としてデータ収集に絡めて日本語データとその前処理について考察する。また本研究が最終的に望むものは、キャラクタ性を持った対話可能なエージェントを作ることであることを強調する。
   　もう少し言及すると、本研究ではデータからモデルにかけて5つの少テーマについて研究を行った。概要をそれぞれ説明すると以下のようになる。
   1. 日本語データの取り扱いについて
      　我々は一般に日本語を話しており、それを用いた対話システムの構築が本研究の主目的である。しかし機械学習等のデータセットや実験で多く使われているのは、日本語とは使っている文字や文型で大きく異なっている、英語のものが多い。その前提のもとで日本語のデータ、特にセンテンスに対して、どのような性質があるのかを調査し、また提案する漢字→ひらがな変換という前処理とそれによって得られる性質についても議論を行う。
   2. 文抽出を念頭においた不均衡分散・サイズの分類問題
      　テキストのカテゴリ分類を考えたとき、一般には $n$ 個のカテゴリの中から任意の文が入力されることを想定している。今回はそれとはやや問題設定が異なり、いくつかの文をカテゴリ $1 \cdots n-1$ 、それ以外をカテゴリ $n$ として扱うことを主問題した。しかしデータを設定・収集することが困難であったため、一部画像認識の問題として議論を行う。
   3. 機械翻訳システムを用いた対話モデル
      　一対一対話を行う際に、機械翻訳システムを用いることがある。今回はそれを、問題を文脈に依存しない発話に対する反応を学習することに再設定し、Transformer という先日 [fn:transformer] State-Of-The-Art を獲得した機械翻訳の手法を用いて実験、有名な手法である Sequence to Sequence Attention を用いた一対一対話モデルと比較を行う。
   4. 文章のスタイル変換
      　文章のスタイルとは、例えば口調や訛り、書き言葉や話し言葉といったものを指す。これは日本語で特に顕著に見られるもので、テキスト上でもこれを確認することで相手のペルソナをある程度想定することができる。本研究が日本語を対象としていること、キャラクタ性を持たせたいというモチベーションがあることから文章に特定のスタイルを持たせることを問題として取り上げる。
   5. CoLAタスクを応用した対話システムのエラー検知
      　対話システムを小問題に分割して解く弊害として、それぞれの問題でエラー(不適切な出力)が出てしまうというものがある。これに対処するため、特に何らかのモデルから生成された文に対しそれが自然であるかどうかを評価するモデルを作成し実験する。

*** abstract :noexport:
  　まず受付やオンラインチャットなどにおいて対話システムの需要が増えていること、Amazon AlexaやSiriなどを例に出して説明する。次にキャラクタ性を持ったマルチモーダル対話システムとして、りんなを例に上げる。
  　その実装例として、Amazon Alexa Prize のコンテストを例に出す。
  　本研究の目的として、日本語環境下で、りんなのような機能を持つシステムを構築すること、ゲームAIへの転用などを視野にいれていることを説明する。そしてシステムの概要として、対話システムという大問題に対して、いくつかの小問題に分割し、それらを組み合わせるモジュール分割という手法を用いることにしたことを説明する。
[fn:rinna] https://twitter.com/ms_rinna
[fn:alexaprize] https://developer.amazon.com/alexaprize
[fn:hred] HRED (\cite{1507.02221}) や VHRED (\cite{1605.06069}) があるが、発話の多様性を得ること(一般的な受け答えを学んでしまい、同じような文ばかり生成してしまうこと)やデータを十分に集めることが難しいなど課題がある。
[fn:multimordule] 日本で人気を得ている ``マルチモーダルエージェントAI'' とは、複数のソースから問題を見直すという特徴があるが、これは複数のモデルを使っているという意味で同じではあるが、問題を分割しようとしているわけではないという点でこの研究と大きく違うと言えるだろう。
[fn:transformer] 2017年12月時点
** 本論文の構成
第1章に本論文の概要とその構成について説明を行い、第2章で関連研究を紹介し、第3章で本研究で掲げるシステムの全体像を示す。そして第4章から第9章にかけては [[研究背景及び目的]] で述べたテーマについての順に議論する。その後付録として補足をまとめたものを 第10章 として示す。最後に議論として本論文のまとめ、今後の展望について述べる。

*** abstract :noexport:
   　1章として論文の導入をしていること。2章で対話システムの関連研究として1章の研究背景で紹介した(Amazon Alexa Prizeやりんな)の概要を説明していること。3章として対話システム全体の実装として目標としている構成図を示していること。4章については日本語のデータをどのように扱うべきか考察したこと。5章から8章にかけてはそれぞれのモジュールに対する研究について説明をしていること。9章に対してはそれぞれの章で説明が不足しているであろう内容を補足するための付録であること。を説明する。
* 対話システムの関連研究
対話システムの関連研究としては、 [[研究背景及び目的]] で述べたように Amazon Alexa Prize というコンテストや、Microsoft社のりんなを挙げることができるだろう。Microsoft社のりんなは日本語雑談対話(\cite{rinna_article}) を実現しており、2018年現在Twitterなどで活動をしている。Amazon Alexa Prize は Amazon Alexa という音声会話を行うことのできる端末に搭載する対話システムを競う大会である。評価対象はユーザの印象であり、別の指標として対話時間が公開される。2018年度のAmazon Alexa Prizeでは平均10分程度の対話を行うことの出来たシステム [fn:aap] が優勝した。顔や体といったテキスト以外の情報を用いることの出来ない対話システムでこのような結果が得られたことは注目すべきことである。
　いずれも複数のモデルを組み合わせて構成されており、例えば言語理解部と文章生成部、そして本研究で取り扱わないものとしては、音声理解部と音声生成部を挙げることができる。またりんなに関してはそれに加えて画像認識部などの対話以外の [fn:rinna2] システムも構築している。


#+ATTR_LATEX: :width 8cm
#+CAPTION: りんなのフレームワーク
#+NAME: fig:RINNA_FRAMEWORK
[[./img/rinna-framework.png]]

[fn:aap] 2018年度優勝は カルフォルニア大学デイビス校のチームが開発したの Gunrock というシステムであり、また2017年度優勝はワシントン大学のチームが開発した Sounding Board というシステムである。この2つについての詳細は [[#extra_rsearch]] で紹介する。なぜこれらを追実装しなかったのかという疑問もあるかもしれないが、いずれも大規模なデータを必要とする (例えば10Mを超える会話データ) ため、個人でそれを実装することは不可能である。
[fn:rinna2] 対話をテキストやそれを示す音声のみのコミュニケーションと定義した場合。実際には対話には身振り手振り、表情といった要素が複雑に絡んでいる。そのため2017年頃からは、表情を考慮した対話システムが提案され(\cite{1812.01525})研究されている。

** abstract :noexport:
  　関連研究として、Amazon Alexa Prizeの問題設定の説明、 2018 年、2017年の最優秀賞団体がモジュール分割して問題を解決したことを説明する。りんなの概要についても紹介する。
* 想定する対話システムの全体像
  　全体像図のグラフを示す。
  　それぞれの問題をリストとして示す。
* 日本語データの取り扱いについて
  　日本語データは英語データに比べていくつかの問題があること。その例として。語尾の多彩な変化や漢字かな問題があることを紹介する。また一般に公開されている対話データセットをどのように用いるべきなのかについての考察を行ったこと、漢字かな問題に対して単語分散を得るための手法を二種類想定し、それぞれの性質を比較する。
** 調査) 発話データ
   　発話データとして、2018年12月25日 23:00頃 から翌 26日 10:00頃 までに収集した7万件のTwitterデータを収集し、その性質を観測した。
*** フィルタ
    　フィルタとして、タグや宛名、リンクを省いた後、4字以上、60字以下のデータを対象とした。その理由として、長文のツイートは説明の内容が含まれること、このデータの取扱先として深層学習を中心にした機械学習(要約タスクを除く)を想定しているため、あまり長すぎるテキストは切り落とす可能性があること、短すぎるつぶやきはリンクやタグのみのツイートが多かったことを挙げる。
*** 調査結果
    　調査結果を表を用いて示す。そして後述の実験である極性判定実験のために抽出できたデータが10%程度であったことを説明する。
** 調査) 対話データ
   　対話データとして、Twitterのデータ、一般公開されている書き起こしの対話コーパスの内容について言及し、前者に比べ後者は文字だけでは学習することが難しい(背景知識が必要である)ことを説明する。
** 問題設定
   　英語では単語分散を得るために space で区切られた単語ごとに id を振る手法が有名であったが、最近では単語の一部 subword を用いる手法が出てきている。その例として google の出した wordpiece があることを紹介する。
   　(単語分散を得る際に、日本語は英語と違って、単語ごとに分割されていないことを上げ、WordPirce SentencePiece 単語分割を用いる手法があることを紹介し、最近では単語分散を得ることのできる有力な手法としてELMo、 BERT が台頭してきたことを紹介し、そこでは SentencePiece が有力であるという実験結果が出ていることを示す。)
   　今回は単語分割+subwordを用いることを想定し、1. fasttext の skipgram を用いて漢字かな入り混じり、かなのみのテキストに対して語彙数、損失、ある単語の類似語について実験をすること 2. 得られた単語分散を用いて極性判定の実験をすることを説明する。
** 実験) 漢字かな問題に対する単語分散取得
*** 実験概要   
    単語分散を得るためのコーパスとしてWikipediaコーパスを用いたことなど、実験の概要を示す。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
** 実験) 得られた単語分散を用いた極性判定
*** 実験概要
    [[実験) 漢字かな問題に対する単語分散取得]] で得た単語分散を用いて極性判定を行ったこと、極性判定のデータセットは [[調査) 発話データ]] で抽出・編集したデータであることを示す。(抽出・編集条件 を再度示す)
　　また実験に用いたネットワークについて説明する (CNN-RNN)
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 文抽出を念頭においた不均衡分散・サイズの分類問題
** 問題設定
   入力された文が特定の意味を持った文であるかどうかを抽出する問題において、どのように分類するべきなのかを検討する。
   一般的なクラス分類との比較として、この問題は特定の意味を持った文章の集合であるクラスと、それ以外のクラスとでデータの分散やデータの数に大きな差があること、画像認識と違ってアップサンプリング(水増し)が難しいことを問題点としてあげ、まず一般的に用いられている分類問題として解き、次に提案する手法である点類似度を用いたクラス分類を説明する。
   (特定の文章で分岐を行い、その組み合わせを用いてユーザとの対話を試みる、シナリオ型対話システムがあることにも触れる。)
   考察は比較のためにすべての実験のあとにまとめることを説明する。
** 実験) 自然言語処理の場合における一般的なクラス分類
   news20 というデータセットを用いてCNNを用いた1クラス分類(1カテゴリ：19カテゴリ)を行う。相手のクラスの分散が想定よりも小さいことを注記する。
** 実験) 画像タスクに置換した場合における一般的なクラス分類
   imagenet の画像タスクで、猫・犬分類と猫・ランダム画像でのクラス分類を行う。
** 実験) 自然言語処理の場合における点類似度を用いたクラス分類
   BERTモデルを用いて、文章類似度を測り、それを用いてクラス分類を行う。
** 実験) 画像タスクに置換した場合における点類似度を用いたクラス分類
   画像の類似度を測り、それを用いてクラス分類を行う(実験が間に合えば)
** 考察
   後者のほうが拡張性があること、前者の場合に猫・犬よりも猫・ランダムのほうが精度が悪くなる傾向があることを指摘する。
* 機械翻訳システムを用いた対話モデル
** 問題設定
   　反射応答のような問題について、機械翻訳を用いて発話を行わせることを提案、その手法として昨今機械翻訳の分野でSOTAを取っていたTransformerを用いることを実験し、その性能を考察する。
** 実験) Seq2Seq Attention と Transformer の精度比較
*** 実験概要
    データセットなどの実験概要を示す
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 文章のスタイル変換
** 関連研究
   この分野の関連研究として seqence to better sequence(本実験)や、(夏季レポートに記載したもの)　を例に挙げる。(画像認識の分野におけるスタイル変換についても触れておく必要があれば触れておく)
** 問題設定
   書き言葉→話し言葉変換を行うことなどを説明する。またこの実験における話し言葉、書き言葉の定義についても言及しておく。
** 実験) 書き言葉→話し言葉のスタイル変換
*** 実験概要
    データセット、モデルの説明を行う。
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* CoLAタスクを応用した対話システムのエラー検知
** 問題設定
   　深層学習を用いた対話モデルや、文生成のモデルを用いる際に出てしまう可能性のある不自然な文章を検出するという問題設定について説明する。
** 実験) 対話システムのエラー検知
*** 実験概要
    　BERTを用いて実験したことを示す。
    　(このモデルを作成するにあたり文章の自然さを評価するための CoLA タスクというものに注目し、これを解いている BERT と呼ばれるモデルを用いる。)
*** 実験結果
    実験結果を示す。
*** 考察
    考察を示す。
* 付録
  この付録の存在意義について説明する。(論文の補足であることを説明する)
** 対話システムの関連研究
:PROPERTIES:
:CUSTOM_ID: extra_rsearch
:END:

*** Sounding Board
    　Sounding Board
*** Gunrock
    Amazon Alexa Prize
** 日本語データの取り扱いについて
*** 単語分割
    単語分割
*** Word Piece
    Word Piece
*** Sentence Pieces
    Sentence Pieces
*** Skipgram
    Skipgram
*** CNN-RNN
    CNN-RNN
** 質問文抽出を念頭においた不均衡分散・サイズの分類問題
*** 画像データ
    画像データ
*** 文データ
    文データ
** 機械翻訳システムを用いた対話
*** Seq2Seq Attention
    Seq2Seq Attention
*** Transformer
    Transformer
** 文章のスタイル変換
*** Sequence to Better Sequence
    Sequence to Better Sequence
*** CopyNet
    CopyNet
*** Denoising Auto Encoder
    Denoising Auto Encoder
** CoLAタスクを応用した対話システムのエラー検知
*** BERT
    BERT
* 結論
** 今後の課題
   今回できなかった文生成の問題・論文に載せることのできなかった推論の内部状態の更新等について言及する。また精度向上や今後取り組みたい問題設定(Unityなどで仮想世界を作り、その中で対話を行えるようにするエージェント作成したい旨)について話す。


#+LATEX: \printbibliography

#+TITLE: 進捗報告
#+AUTHOR: 江畑 拓哉
#+EMAIL: s1611350@u.tsukuba.ac.jp
#+DATE: 2018-12-12 Wed
#+LATEX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [bigger]
#+latex_header: \mode<beamer>{\usetheme{Madrid}}
#+LATEX_HEADER_EXTRA:
#+DESCRIPTION:
#+KEYWORDS:
#+SUBTITLE:
#+LATEX_COMPILER: platex
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+OPTIONS: broken-links:nil c:nil creator:t d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:t f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+OPTIONS: tasks:t tex:t timestamp:t title:t toc:nil todo:t |:t
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.2.2 (Org mode 9.1.14)
#+startup: beamer
#+BEAMER_FRAME_LEVEL: 2

* 全体像
  #+CAPTION: 全体像
  #+ATTR_LATEX: :width 10cm
  [[./figure3.png]]
* 今回報告する部分
  - スタイル変換 (Style Transfer)
  - 1 : 1 対話 (Topic Dialogue)
  - 不均衡データ分散なデータセットと不均衡データ数なデータセットの関係 (Question Detection)
  - 日本語言語理解タスクのためのSubword
  - 今後の実験計画
* スタイル変換
** スタイル変換
   - センテンスにおける口調を変換するというタスク。
   - 今回主に取り扱うのははです・ます調<=>話し言葉への変換。
   - データセットは自作の @並行な@ ものを使用 (データ数が少ないのでLossやAccへの言及はしない)
   - 3つの手法で実験し、その結果を観察する。
** Sequence to better sequence
   - 対象とするデータ: @非並行な@ 2つのスタイルを持つセンテンスの集合
*** 学習内容                                                        :B_block:
    :PROPERTIES:
    :BEAMER_env: block
    :END:
    1. 入力文と出力文を一つのVAEに通し潜在表現を得る
    2. 入力文のスコアを0、出力文のスコアを1となるように潜在表現を評価するFFを学習する
    3. 何らかの入力 $\bm{x}$ に対してそのスコアを 1 になるように潜在表現を調整することで、スタイルが付与された文 $\bm{x'}$ を得る。
    　実験ではこれと、更に多くの汎化性能を得るため、VAEの入力にノイズ(一部を未知語に変換する)をかけたものの実験を行った。
** CopyNet
   - 対象とするデータ: @並行な@ 2つのスタイルを持つセンテンスの集合
*** 学習内容                                                        :B_block:
    :PROPERTIES:
    :BEAMER_env: block
    :END:
    1. 入力文を通すRNNから最後の出力(意味ベクトル)・それぞれの単語を表すベクトルを得る
    2. 出力文を生成するRNNと演算を行う
    3. 出力文を生成できるようにそれぞれのベクトルに対する重み付けなどを学習する
    　本来は機械翻訳のタスクで使用されている手法だが、今回対象とする問題の、入力文・出力文が非常に似ているという性質からこの手法を用いた。
** 実験結果
|---------------+------------------------+----------------------|
| 実装          | 入力                   | 出力                 |
|---------------+------------------------+----------------------|
| S2BS          | 応援する。             | 応援してる。         |
|               | 今日は寒かった。       | 今日は寒かった。     |
|               | 夕飯は？               | 夕飯はどうしようか？ |
|               | 早く寝たい。           | 早く寝た方がよいね。 |
|               | おはようございます。   | おはよう。           |
|---------------+------------------------+----------------------|
| S2BS with DAE | S2BSと同じ             |                      |
|---------------+------------------------+----------------------|
| CopyNet       | おはようございます。   | おはよう。           |
|               | 今日は良い天気ですね。 | 今日は良い天気。     |
|               | こんにちは。           | こんにちは。         |
|               | 最近調子はどうですか？ | 最近調子はどう？     |
|               | 頑張るぞい！           | 頑張るぞい！         |
|               | 進捗どうですか？       | 進捗どう？           |
|---------------+------------------------+----------------------|
$\star$ S2BS : Sequence to better sequence
$\star$ S2BS with DAE : Sequence to better sequence with DAE

** 考察
   - S2BSとS2BS with DAE にはほとんど差異が見られなかった。
   　これがデータ数によるものなのか、本当になんの意味もないのかは不明である。
   - S2BS、CopyNet のいずれでも入力が正規化されていなくても問題なく変換ができることがわかった。
   - S2BS は CopyNet に比べて表現力が大きいように感じられる。
     学習内容から用意に予測できる。
   
* 1 : 1 対話
** 1 : 1 対話
   入力文1文に対して、前後の文脈は考慮せずに出力文を作成する問題。
** Seq2Seq with attention
   以前紹介した Sequence to Sequence という一般的に機械翻訳で用いられる手法に attention という機能を追加したもの。入力文の単語としての性質を出力文により強く影響させることができる。
** Transformer
   attention 機能により注目した手法。RNNやCNNは用いていないという点が革新的。現役で優秀な成績を収めている機械翻訳の手法。
   
** Beam search
   今回紹介する Beam search とは、主に出力文を生成する際に貪欲にその場の最大確率を選択せずに、いくつかの出力文を生成し、それらの中で最も良いものを選択するためのアルゴリズムであり、これを用いることで同じモデルでもより良い結果を得ることができる。
   
** 実験
   [間に合えば書きます。]
** 実験結果
** 考察
* 不均衡データ分散なデータセットと不均衡データ数なデータセットの関係
** 本来の問題
   　任意の入力文からいくつかの質問・文を抽出したい。
     以下の理由から画像認識の問題として(1)の問題を設定した。
   - データを十分に用意できない。
   - 2つの選択肢が考えられる。
     1. シンプルなクラス分類 (文A、文B ... その他)
     2. 文章類似度を活用したクラス分類 
        \begin{eqnarray*}
          \max_{i}f(similarity(x, Y_i_j))\\
          x\dots input sentence\\
          Y_i\dots set\ of\ sentences\ in\ class\ i
        \end{eqnarray*}

** 設定した問題
   ネコ画像の集合 $X$ と、イヌの画像の集合 $Y$ 、ランダムな画像の集合 $Z$ を用いる。
   $X-Y$ $X-Z$ の2値分類問題において、データ数の比率を変化させながらそのLoss, Accを比較する。
** 実験
   6層CNN を用いて実験を行った
   - 入力画像は $28 \times 28$ の 3 チャンネル
   - 出力は $2\times batch size$ (多クラス分類への拡張を想定しているため)
   - 最適化関数は Adam を用いた
   - epoch は十分に学習ができるまでとした
** 実験結果
   
** 考察
* 日本語言語理解タスクのためのSubword
** Subword
** 元の問題
** 設定した問題
** 実験
** 実験結果
** 考察
* 今後の実験計画
  - 極性判定
  - CoLA タスクを用いた自然言語判定
  - 文章類似度を用いた

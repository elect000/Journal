
#+OPTIONS: ':nil *:t -:t ::t <:t H:2 \n:t arch:headline ^:nil
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:nil e:nil email:t f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:nil title:t toc:t todo:t |:t
#+TITLE: Krylov 部分空間法
#+SUBTITLE: 
#+DATE: 
#+AUTHOR: 情報科学類３年 江畑 拓哉 (201611350)
#+EMAIL: 
#+LANGUAGE: ja
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode 9.0.2)

#+LATEX_CLASS: mybeamer
#+LATEX_CLASS_OPTIONS:[dvipdfmx,10pt,presentation]
#+LATEX_HEADER: \useoutertheme[subsection=false]{smoothbars}
#+LATEX_HEADER: \setbeamertemplate{footline}[page number]
#+LATEX_HEADER: \setbeamercolor{page number in head/foot}{fg=black}
#+LATEX_HEADER: \setbeamerfont{page number in head/foot}{size=\normalsize}
#+LATEX_HEADER_EXTRA:
#+DESCRIPTION:
#+KEYWORDS:
#+SUBTITLE:
#+STARTUP: indent overview inlineimages
#+STARTUP: beamer
#+BEAMER_FRAME_LEVEL: 2

* 導入
** 導入
:PROPERTIES:
:BEAMER_opt: allowframebreaks
:END:
- 次元削減を行うために、切り詰めた(truncated)SVD(特異値分解)やPCR(主成分回帰)を用いることがある。
  この時、右辺はどのような基底ベクトル $z_i$ の選択にも影響を与えない。
  $\Rightarrow$ [Example7.2] 残差の減衰率は $q_2$ の方が $q_1$ に比べてかなり緩くなっている。
- 多くの場合、任意の右辺の基底ベクトルの数で作られる関数としては、 _残差は急速に減衰してほしい_ 。
  つまり右辺には、基底ベクトルの選択に何らかの影響を与えて欲しい。
- この解法として Lanczos-Golub-Kahan (LGK) 二重対角化 (bidiagonalization) がある。
*** 用語 
:PROPERTIES:
:BEAMER_ENV: block
:BEAMER_COL: 1.00
:END:
- 特異値分解
  任意の $\bm{A}\ where\ \bm{A} \in \mathbb{R} ^{m \times n}$ に対して 

  \begin{align*}
  \bm{A} = \bm{U} \bm{\Sigma} \bm{V}
  \ where\ \bm{U} &\in \mathbb{R}^{m \times m}\ is\ orthogonal\\
   \bm{V} &\in \mathbb{R}^{n \times n}\ is\ orthogonal\\
   \bm{\Sigma} &\in \mathbb{R}^{m \times n}\ is\ diagonal
               & \sigma_1 \geq ... \geq \sigma_r > 0
  \end{align*}

  となる $\Sigma$ を求めること 
- Truncated SVD
  SVD の近似
- 主成分回帰
  独立変数から共分散行列を求め、固有値分解をして主成分を抽出し(PCA(主成分分析))、その主成分を用いて回帰分析をする手法

** 
*** LGK 二重対角化
:PROPERTIES:
:BEAMER_ENV: block
:BEAMER_COL: 1.00
:END:
  - 線形代数の分野で用いられていおり、 Lanczos 二重対角化とも呼ばれる。
  - 計量科学やその他の分野では部分的最小二乗法(PLS(Partial Least Squares/Projection Latent structures))に密接して関連した方法として知られている。
  - Krylov 部分空間法 の中から来た手法であり、疎な線形問題(sparse linear systems)や、固有値・特異値の計算で用いられる。
** 
　Krylov 部分空間法は再帰的であるが、始めに導出として扱うのはハウスホルダー変換を用いて行列を二重対角化する手法である。

* ハウスホルダー変換を用いた二重対角化 
** ハウスホルダー変換を用いた二重対角化
　密行列 $C\in\mathbb{R}^{m\times(n+1)}$ の SVD を計算するアルゴリズムの最初のステップは、左から右へハウスホルダー変換をし、上二重対角の形に $\bm{C}$ を変換することである。
　 $m > n$ を仮定すると、以下の形が求まる。

\begin{align*}
\bm{C} &= \bm{P}\begin{pmatrix}\hat{\bm{B}}\\\bm{0}\end{pmatrix}\bm{W}^T\\
where\ \bm{P}, \bm{W} \ &is\ orthogonal\\
      \bm{B} \ &is\ upper bidiagonal \tag{7.5}
\end{align*}
　この自己圧縮は他の目的でも有用。
　$\Rightarrow$ 疎・密行列の最小二乗問題の近似解を求める際など

** ハウスホルダー変換を用いた二重対角化の例
:PROPERTIES:
:BEAMER_opt: allowframebreaks
:END:
例として、 $\bm{C}\in\mathbb{R}^{6 \times 5}$ を用いて説明する。※ _$m = 6,\ n + 1 = 5$_
まず 1 列目の非対角成分を、左側からかける変換行列 $\bm{P}^T_1\in\mathbb{R}^{6\times6}$ を用いて 0 にする。

\begin{align*}
\bm{P}^T_1 \bm{C} = \bm{P}^T_1
\begin{pmatrix}
\times & \times & \times & \times & \times \\
\times & \times & \times & \times & \times \\
\times & \times & \times & \times & \times \\
\times & \times & \times & \times & \times \\
\times & \times & \times & \times & \times \\
\times & \times & \times & \times & \times
\end{pmatrix}
=
\begin{pmatrix}
\ast & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast & \ast 
\end{pmatrix}
\end{align*}

** 
　次に、別の右からかける変換行列 $\bm{W}_1$ を用いて 1 行目の 3 番目の要素から右側をすべて 0 にします。 $\bm{W}_1$ は以下のように表すことができる。
\begin{align*}
\mathbb{R}^{5\times5} \ni \bm{W}_1 = 
\begin{pmatrix}
1 & \bm{0} \\
\bm{0} & \bm{Z}_1 
\end{pmatrix}
where\ \bm{Z}_1\ &is\ Householder\ transformation
\end{align*}
　これを用いた変換は 1 列目の要素に対しては何も影響しない。つまり前に行った 1 列目の非対角成分を 0 にした変換の効果は打ち消されない。結果は以下のようになる。
\begin{align*}
\bm{P}^T_1\bm{C}\bm{W}_1 =
\begin{pmatrix}
\times & \times & \times & \times & \times \\
0 & \times & \times & \times & \times \\
0 & \times & \times & \times & \times \\
0 & \times & \times & \times &  \times \\
0 & \times & \times & \times &  \times \\
0 & \times & \times & \times &  \times
\end{pmatrix}
\bm{W}_1
=
\begin{pmatrix}
\times & \ast & 0 & 0 & 0 \\
0 & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast & \ast \\
0 & \ast & \ast & \ast &  \ast \\
0 & \ast & \ast & \ast &  \ast \\
0 & \ast & \ast & \ast &  \ast
\end{pmatrix}
=: \bm{C}_1
\end{align*}

** 
　同様の手法を用いて 2 列目の対角成分よりも下の成分を 0 にする変換行列 $\bm{P}_2$ を $\bm{C}_1$ にかける 。但し 1 行目の要素については値が変わらないようにする。
　すると、 $\bm{P}_2$ は以下のように表すことができる。
\begin{align*}
\mathbb{R}^{6\times 6} \ni \bm{P}_2 =
\begin{pmatrix}
1 & \bm{0}\\
\bm{0} & \tilde{\bm{P}_2}
\end{pmatrix}
where\ \tilde{\bm{P}_2} \in \mathbb{R}^{5\times5}\ is\ Householder\ transformation
\end{align*}
　これを適用して、
\begin{align*}
\bm{P}^T_2\bm{C}_1 = 
\begin{pmatrix}
\times & \times & 0 & 0 & 0\\ 
0 & \ast & \ast & \ast & \ast\\
0 & 0 & \ast & \ast & \ast\\
0 & 0 & \ast & \ast & \ast\\
0 & 0 & \ast & \ast & \ast\\
0 & 0 & \ast & \ast & \ast\\
\end{pmatrix}
\end{align*}
** 
　そして同様に右からかける変換行列 $\bm{W}_2$ は以下のように表すことができる。
\begin{align*}
\bm{W}_2 =
\begin{pmatrix}
\bm{I}_2 & \bm{0}\\
\bm{0} & \bm{Z}_2 
\end{pmatrix}
,\ 
\bm{I}_2 = 
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
\end{align*}
　これも $\bm{W}_1$ 同様 $\bm{P}_2$ で 0 にした部分を汚すことなく 2 列目の 4行目以降の要素を0にする。
\begin{align*}
\bm{P}^T_2\bm{C}_1\bm{W}_2 = 
\begin{pmatrix}
\times & \times & 0 & 0 & 0 \\  
0 & \times & \ast & 0 & 0 \\
0 & 0 & \ast & \ast & \ast \\
0 & 0 & \ast & \ast & \ast \\
0 & 0 & \ast & \ast & \ast \\
0 & 0 & \ast & \ast & \ast \\
\end{pmatrix}
=: \bm{C}_2
\end{align*}
** 
　この操作を繰り返すことで最終的に以下の形を得る。
\begin{align*}
\bm{P}^T\bm{C}\bm{W} &=
\begin{pmatrix}
\times & \times & & & \\
 & \times & \times& & \\
 & & \times & \times &  \\
&&&\times & \times  \\
&&&& \times   \\
&&&&& \\
\end{pmatrix}
=
\begin{pmatrix}
\hat{\bm{B}}\\
\bm{0}
\end{pmatrix} \\
where\ \bm{P} &= \bm{P}_1 \bm{P}_2 \cdots \bm{P}_n \in \mathbb{R}^{m \times m}\\
\bm{W} &= \bm{W}_1 \bm{W}_2 \cdots \bm{W}_{n-2} \in \mathbb{R}^{(n+1)\times(n+1)}
 \tag{7.6}
\end{align*}
※ $\bm{W}$ が $n-2$ までであるのは、上二重対角であるから。

　一般的に上で示された $\bm{P}$ , $\bm{W}$ はハウスホルダー変換の積であり、
** 
\begin{align*}
\hat{\bm{B}} =
\begin{pmatrix}
\beta_1& \alpha_1& & & \\
&\beta_2& \alpha_2&  & \\
&&\ddots& \ddots &   \\
&&& \beta_n& \alpha_n   \\
&&&& \beta_{n+1}   \\
\end{pmatrix}
\in \mathbb{R}^{(n+1)\times(n+1)}
\end{align*}

　は上二重対角行列である。
　これらは、この章の残りの部分で用いられる直交行列を生成するための構造を持っている。
** 
:PROPERTIES:
:BEAMER_opt: allowframebreaks
:END:
*** 命題 7.3
:PROPERTIES:
:BEAMER_ENV: block
:BEAMER_COL: 1.00
:END:
　二重対角分解 (7.6) 式における $\bm{P}$ の列を $\bm{p}_i,i=1,2,\dots,m$ として表すと以下のように表すことが出来る。
\begin{align*}
\bm{p}_1 = \bm{\beta}_1 \bm{c}_1,\ \bm{W} = 
\begin{pmatrix}
1 & \bm{0}\\
\bm{0} & \bm{Z}
\end{pmatrix}
\ where\ \bm{Z}\in\mathbb{R}^{n \times n}\ is\ orthogonal
\end{align*}
$c_1$ は $\bm{C}$ の最初の列である。
** 
*** 証明
:PROPERTIES:
:BEAMER_ENV: block
:BEAMER_COL: 1.00
:END:
　 $i = 1$ の場合は、 $\bm{P}^T \bm{c}_1 = \beta_1 \bm{e}_1$ であったことから明らかである。これ以降の場合では、 $\bm{W}_i$ が以下の構造で表されていたことからわかる。
\begin{align*}
\bm{W}_i &=
\begin{pmatrix}
\bm{I}_i & \bm{0}\\
\bm{0} & \bm{Z}_i 
\end{pmatrix} \\
where\ \bm{I}_i &\in \mathbb{R}^{i \times i}\ is\ identicaly\ matrices \\
\bm{Z}_i &are \ orthogonal
\end{align*}

** 
　ハウスホルダー変換を用いた二重対角化への削減は $4mn^2 - 4n^3 / 3$ flopsかかる。
もし $m \gg n$ ならば、 $\bm{A}$ を上三角行列にして、 $\bm{R}$ 要素を二重対角化したほうが良い。
※R とは LU 分解で言う U 要素(LU 分解の別名は LR分解)
** 最小二乗問題
:PROPERTIES:
:BEAMER_opt: allowframebreaks
:END:
　最小二乗問題 $\min_x||\bm{b}-\bm{A}\bm{x}||_2,\ where\ \bm{A}\in\mathbb{R}^{m\times n}$ を解く場合について考える。
　二重対角化において $\bm{C} = (\bm{b}\  \bm{A})$ とした場合、同等の二重対角化最小二乗問題(bidiagonal least squares problem)を得ることが出来る。式(7.6) と命題 7.3 より以下を得る。
\begin{align*}
\bm{P}^T\bm{C}\bm{W} = \bm{P}^T
\begin{pmatrix}
\bm{b} & \bm{A}
\end{pmatrix}
\begin{pmatrix}
1 & \bm{0}\\
\bm{0} & \bm{Z}
\end{pmatrix}
=
\begin{pmatrix}
\bm{P}^T\bm{b}& \bm{P}^T\bm{A}\bm{Z}
\end{pmatrix}
=
\begin{pmatrix}
\beta_1 & \bm{B}\\
\bm{0} & \bm{0}
\end{pmatrix} \tag{7.7}
\end{align*}
\begin{align*}
&where \\
&\bm{B} =
\begin{pmatrix}
 \alpha_1& & & \\
\beta_2& \alpha_2&  & \\
&\ddots& \ddots &   \\
&& \beta_n& \alpha_n   \\
&&& \beta_{n+1}   \\
\end{pmatrix}
\in \mathbb{R}^{(n+1)\times n}
\end{align*}
** 
　そして $\bm{y} = \bm{Z}^T\bm{x}$ として残差の 2 ノルムを以下のように書くことができる。
\begin{align*}
||\bm{b} - \bm{A}\bm{x}||_2 &=
|| \begin{pmatrix}
\bm{b} & \bm{A}
\end{pmatrix}
\begin{pmatrix}
1 \\
-\bm{x}
\end{pmatrix}||_2 = 
||
\bm{P}^T
\begin{pmatrix}
\bm{b} & \bm{A}
\end{pmatrix}
\begin{pmatrix}
1 & \bm{0} \\
\bm{0} & \bm{Z}
\end{pmatrix}
\begin{pmatrix}
1 \\ - \bm{y}
\end{pmatrix}
||_2 \\
&= ||
\begin{pmatrix}
\bm{\bm{P}^T\bm{b}} & \bm{P}^T\bm{A}\bm{X}
\end{pmatrix}
\begin{pmatrix}
1 \\
-\bm{y}
\end{pmatrix}
||_2 =
|| \beta_1\bm{e}_1 - \bm{B}\bm{y}||_2 \tag{7.8}
\end{align*}
　もし平面回転の操作によって $\bm{B}$ が上二重対角行列に変換される場合、この二重対角最小二乗問題 $\min_y||\beta_1\bm{e}_1 - \bm{B}\bm{y}||_2$ は $O(n)$ flopsで解くことが出来る。
* LGK 二重対角化
** LGK 二重対角化
　ここでは前で述べた二重対角化手法ではない別の手法を扱う。この手法は式(7.7)の計算を再帰的に解く。これを _LGK 二重対角化_ という。式(7.7)の最後の式は以下のように書くことが出来る。
\begin{align*}
\bm{P}^T\bm{A}=
\begin{pmatrix}
\bm{B}\bm{Z}^T\\
\bm{0}
\end{pmatrix}  where \ \bm{B}\bm{Z}^T \in \mathbb{R}^{(n+1)\times n}
\end{align*}
** 
 これは更に詳しく書けば以下のようになる。
\begin{align*}
&\bm{A}^T
\begin{pmatrix}
\bm{p}_1& \bm{p}_2&\cdots & \bm{p}_{n+1}
\end{pmatrix}
= \bm{Z} \bm{B}^T  \\
&= 
\begin{pmatrix}
\bm{z}_1 & \bm{z}_2 &\cdots &\bm{z}_n
\end{pmatrix}
\begin{pmatrix}
\alpha_1& \beta_2& & & & &&\\
&\alpha_2& \beta_3&  & &&&\\
&&\ddots& \ddots &   &&&\\
&&&& \beta_i &&\\
&&&& \alpha_i && \\
&&&&&\ddots & \ddots & \\ 
&&&&&& \alpha_n & \beta_{n+1}   \\
\end{pmatrix}
\end{align*}
　両辺の $i$ 列 $(i\geq 2)$ を比較すると以下のような式が考えられる。
\begin{align*}
\bm{A}^T\bm{p}_i = \beta_i\bm{z}_{i-1} + \alpha_i \bm{z}_i
\end{align*}
　変形して
\begin{align*}
\alpha_i\bm{z}_i=\bm{A}^T\bm{p}_i - \beta_i\bm{z}_{i-1} \tag{7.9}
\end{align*}
** 
　同様に $i$ 列について、 $(\bm{P}\bm{P}^T\bm{A}\bm{Z}=\bm{P}\bm{B}\bm{Z}^T\bm{Z})$
\begin{align*}
&\bm{A}\bm{Z}
= \bm{A}
\begin{pmatrix}
\bm{z}_1 & \bm{z}_2 & \cdots & \bm{z}_n
\end{pmatrix} \\ 
&= \bm{P}\bm{B} = 
\begin{pmatrix}
\bm{p}_1 & \bm{p}_2 & \cdots & \bm{p}_{n+1}
\end{pmatrix}
\begin{pmatrix}
\alpha_1 &&&&&&& \\
\beta_2 & \alpha_2 &&&&&& \\
& \ddots & \ddots &&&&&\\
&&&& \alpha_i &&& \\
&&&& \beta_{i+1} &&& \\
&&&&&& \ddots & \ddots &\\
&&&&&&& \beta_n & \alpha_n \\
&&&&&&&& \beta_{n+1}
\end{pmatrix}
\end{align*}
** 
　同様に以下のような式が考えられる。
\begin{align*}
\bm{A}\bm{z}_i = \alpha_i\bm{p}_i + \beta_{i+1}\bm{p}_{i+1}
\end{align*}
　変形して
\begin{align*}
\beta_{i+1}\bm{p}_{i+1}=\bm{A}\bm{z}_i -\alpha_i\bm{p}_i \tag{7.10}
\end{align*}

** 
　命題 7.3 より等式 $\beta_1\bm{p}_1 = \bm{b}$ を初期値として等式(7.9), (7.10)を再帰的に解くことが出来る。
*** LGK 二重対角化
1. $\beta_1\bm{p}_1 = \bm{b}, \bm{z}_0 = 0$
2. $for\ i\ =\ 1\ :\ n$
   $\alpha_i\bm{z}_i = \bm{A}^T\bm{p}_i-\beta_i\bm{z}_{i-1}$  
   $\beta_{i+1}\bm{p}_{i+1} = \bm{A}\bm{z}_i- \alpha_{i}\bm{p}_i$
3. end

係数 $\alpha_{i-1}, \beta_i$ は $||\bm{p}_i|| = ||\bm{z}_i||=1$ となるように決定する。

** 
　再帰の終点は $\alpha_i$ 又は $\beta_i$ がゼロと等しくなったときである。最小二乗問題の解法においてこれは明確に定義されている特別な場合であることがわかっているので、終点とみなしても問題がない。
　正確な算術手続きを考えれば、再帰的二重対角化の手続きはハウスホルダー変換を用いた二重対角化と等しくなる。従ってこの過程で生成された $(\bm{p_i})^n_{i=1}$ $(\bm{z}_i)^n_{i=1}$ は $\bm{p}_i^T\bm{p}_j=0 ,\ \bm{z}_i^T\bm{z}_j=0\ if\ i\neq j$ を満たす。
　しかし浮動点計算を考慮すると、生成されるベクトルは再帰の過程で直交性を失ってしまう。
